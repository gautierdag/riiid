{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.style as style\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "style.use(\"fivethirtyeight\")\n",
    "import gc\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import h5py\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from pytorch_lightning.metrics.functional import accuracy\n",
    "from pytorch_lightning import seed_everything\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch import nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "\n",
    "\n",
    "SEED = 69\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading lectures arrays\n",
      "Loading questions arrays\n",
      "CPU times: user 48.5 ms, sys: 2.58 s, total: 2.63 s\n",
      "Wall time: 5.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# This code is needed for dataset\n",
    "train = pd.read_pickle(\"riiid_train.pkl.gzip\")\n",
    "questions_df = pd.read_csv(\"questions.csv\")\n",
    "lectures_df = pd.read_csv(\"lectures.csv\")\n",
    "\n",
    "folder_path = \"data\"\n",
    "print(\"Loading lectures arrays\")\n",
    "lectures_ids = np.load(f\"{folder_path}/lectures_ids.npy\")\n",
    "lectures_parts = np.load(f\"{folder_path}/lectures_parts.npy\")\n",
    "lectures_types = np.load(f\"{folder_path}/lectures_types.npy\")\n",
    "lectures_tags = lectures_df.tag.values\n",
    "\n",
    "print(\"Loading questions arrays\")\n",
    "questions_parts = np.load(f\"{folder_path}/questions_parts.npy\")\n",
    "\n",
    "\n",
    "questions_lectures_parts = np.concatenate([questions_parts, lectures_parts])\n",
    "\n",
    "\n",
    "# process tags\n",
    "def split_tags(t):\n",
    "    try:\n",
    "        return [int(i) for i in t.split(\" \")]\n",
    "    except AttributeError:\n",
    "        return list()\n",
    "\n",
    "\n",
    "# Get tags to be 2D array of shape (Q, T), where Q is question_idx, and T is the max number of tag possible (6)\n",
    "questions_df[\"tags\"] = questions_df.tags.apply(split_tags)\n",
    "questions_tags = pd.DataFrame(questions_df[\"tags\"].tolist(), index=questions_df.index)\n",
    "\n",
    "# map lecture id to new id\n",
    "\n",
    "lectures_mapping = dict(zip(lectures_df.lecture_id.values,(lectures_df.index + 13523).values))\n",
    "lectures_df.lecture_id = lectures_df.index + 13523\n",
    "lectures_tags = pd.DataFrame(lectures_df.tag.values, index=lectures_df.lecture_id.values)\n",
    "\n",
    "questions_lectures_tags = pd.concat([questions_tags, lectures_tags])\n",
    "# pad with max tag + 1\n",
    "questions_lectures_tags = (\n",
    "    questions_lectures_tags.fillna(questions_lectures_tags.max().max() + 1)\n",
    "    .astype(np.int)\n",
    "    .values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_train = pd.read_pickle(f\"cv5_train.pickle\")[\"row_id\"]\n",
    "cv_valid = pd.read_pickle(f\"cv5_valid.pickle\")[\"row_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.1 s, sys: 2.44 s, total: 19.5 s\n",
      "Wall time: 19.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "valid = train[train.row_id.isin(cv_valid)].copy()\n",
    "train = train[train.row_id.isin(cv_train)].copy()\n",
    "del cv_valid, cv_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    \"\"\"\n",
    "    Converts the lecture ids to proper content_ids\n",
    "    Adds the answered_correctly column if not exists\n",
    "    \"\"\"\n",
    "    df.content_type_id = df.content_type_id.astype(bool)\n",
    "    \n",
    "    # prior information\n",
    "    df.prior_question_had_explanation = df.prior_question_had_explanation.astype(np.uint8)\n",
    "    df.prior_question_elapsed_time = df.prior_question_elapsed_time.fillna(0).clip(upper=300000)/300000 #normalizes to 0-1\n",
    "    \n",
    "    # map lecture ids to new content_ids\n",
    "    df.loc[df.content_type_id, \"content_id\"] = df[df.content_type_id].content_id.map(\n",
    "        lectures_mapping\n",
    "    )\n",
    "    # if not answered correctly then add column with\n",
    "    # y = 3 (padding) for all questions and y = 4 for lectures\n",
    "    if \"answered_correctly\" not in df.columns:\n",
    "        df[\"answered_correctly\"] = df.content_type_id.map({False: 3, True: 4})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>user_answer</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_elapsed_time</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>7900</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>32683</td>\n",
       "      <td>124</td>\n",
       "      <td>7876</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>62000</td>\n",
       "      <td>124</td>\n",
       "      <td>175</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>29000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>83632</td>\n",
       "      <td>124</td>\n",
       "      <td>1278</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>189483</td>\n",
       "      <td>124</td>\n",
       "      <td>2064</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    row_id  timestamp  user_id  content_id  content_type_id  \\\n",
       "46      46          0      124        7900            False   \n",
       "47      47      32683      124        7876            False   \n",
       "48      48      62000      124         175            False   \n",
       "49      49      83632      124        1278            False   \n",
       "50      50     189483      124        2064            False   \n",
       "\n",
       "    task_container_id  user_answer  answered_correctly  \\\n",
       "46                  0            0                   1   \n",
       "47                  1            0                   0   \n",
       "48                  2            2                   1   \n",
       "49                  3            1                   0   \n",
       "50                  4            2                   0   \n",
       "\n",
       "    prior_question_elapsed_time  prior_question_had_explanation  \n",
       "46                          NaN                            True  \n",
       "47                      26000.0                           False  \n",
       "48                      29000.0                           False  \n",
       "49                      26000.0                           False  \n",
       "50                      18000.0                           False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.0000001\n",
    "def get_time_elapsed_from_timestamp(arr):\n",
    "    arr_seconds = np.diff(arr, prepend=0) / 1000\n",
    "    return (np.log(arr_seconds + eps).astype(np.float32)-3.5) / 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "## Show effects of transformation \n",
    "times = train.groupby(\"user_id\").timestamp.apply(get_time_elapsed_from_timestamp)\n",
    "times = np.concatenate(times.tolist())\n",
    "sns.boxplot(x=times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Hdf5\n",
    "\n",
    "Only run this once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.04 s, sys: 312 ms, total: 1.36 s\n",
      "Wall time: 1.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = preprocess_df(train) #convert lecture ids to be sequentially following the question_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['row_id', 'timestamp', 'user_id', 'content_id', 'content_type_id',\n",
       "       'task_container_id', 'user_answer', 'answered_correctly',\n",
       "       'prior_question_elapsed_time', 'prior_question_had_explanation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>user_answer</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_elapsed_time</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>7900</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>32683</td>\n",
       "      <td>124</td>\n",
       "      <td>7876</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>62000</td>\n",
       "      <td>124</td>\n",
       "      <td>175</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.096667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>83632</td>\n",
       "      <td>124</td>\n",
       "      <td>1278</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>189483</td>\n",
       "      <td>124</td>\n",
       "      <td>2064</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    row_id  timestamp  user_id  content_id  content_type_id  \\\n",
       "46      46          0      124        7900            False   \n",
       "47      47      32683      124        7876            False   \n",
       "48      48      62000      124         175            False   \n",
       "49      49      83632      124        1278            False   \n",
       "50      50     189483      124        2064            False   \n",
       "\n",
       "    task_container_id  user_answer  answered_correctly  \\\n",
       "46                  0            0                   1   \n",
       "47                  1            0                   0   \n",
       "48                  2            2                   1   \n",
       "49                  3            1                   0   \n",
       "50                  4            2                   0   \n",
       "\n",
       "    prior_question_elapsed_time  prior_question_had_explanation  \n",
       "46                     0.000000                               1  \n",
       "47                     0.086667                               0  \n",
       "48                     0.096667                               0  \n",
       "49                     0.086667                               0  \n",
       "50                     0.060000                               0  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.answered_correctly.replace(-1, 4, inplace=True) # set lecture to token 4 for answered correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd5c862023fd4d3db35d8560d0a5a9cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=338170.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ignore lectures for now\n",
    "hf = h5py.File(\"train_feats.h5\", \"w\")\n",
    "\n",
    "for user_id, data in tqdm(train.groupby(\"user_id\")):\n",
    "    processed_feats = data[\n",
    "        [\n",
    "            \"content_id\",\n",
    "            \"answered_correctly\",\n",
    "            \"timestamp\",\n",
    "            \"prior_question_elapsed_time\",\n",
    "            \"prior_question_had_explanation\"\n",
    "        ]\n",
    "    ].values\n",
    "\n",
    "    hf.create_dataset(f\"{user_id}/content_ids\", data=processed_feats[:, 0], maxshape=(None,))\n",
    "    hf.create_dataset(f\"{user_id}/answered_correctly\", data=processed_feats[:, 1], maxshape=(None,))\n",
    "    hf.create_dataset(f\"{user_id}/timestamps\", data=processed_feats[:, 2], maxshape=(None,))\n",
    "    hf.create_dataset(f\"{user_id}/prior_question_elapsed_time\", data=processed_feats[:, 3], maxshape=(None,))\n",
    "    hf.create_dataset(f\"{user_id}/prior_question_had_explanation\", data=processed_feats[:, 4], maxshape=(None,))\n",
    "\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "Here we define the pytorch Dataset object and a custom collate function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RIIDDataset(Dataset):\n",
    "    \"\"\"RIID dataset.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        user_mapping,\n",
    "        hdf5_file=\"feats_train.h5\",\n",
    "        window_size=WINDOW_SIZE,\n",
    "        only_start=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            user_mapping (np.array): array of all unique user ids \n",
    "            hdf5_file (string): location of hf5 feats file\n",
    "        \"\"\"\n",
    "        # np array where index maps to a user id\n",
    "        self.user_mapping = user_mapping\n",
    "        self.hdf5_file = hdf5_file\n",
    "        self.max_window_size = window_size\n",
    "        # whether to only use the beggining [0,... window_size] elements\n",
    "        self.only_start = only_start \n",
    "\n",
    "    def open_hdf5(self):\n",
    "        # opens the h5py file\n",
    "        self.f = h5py.File(self.hdf5_file, \"r\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_mapping)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # open the hdf5 file in the iterator to allow multiple workers\n",
    "        # https://github.com/pytorch/pytorch/issues/11929\n",
    "        if not hasattr(self, \"f\"):\n",
    "            self.open_hdf5()\n",
    "\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        user_id = self.user_mapping[idx]\n",
    "        length = self.f[f\"{user_id}/answered_correctly\"].len()\n",
    "\n",
    "        window_size = min(self.max_window_size, length)\n",
    "\n",
    "        content_ids = np.zeros(window_size, dtype=np.int64).copy()\n",
    "        answered_correctly = np.zeros(window_size, dtype=np.int64).copy()\n",
    "        timestamps = np.zeros(window_size, dtype=np.float32).copy()\n",
    "        prior_q_times = np.zeros(window_size, dtype=np.float32).copy()\n",
    "        prior_q_explanation = np.zeros(window_size, dtype=np.float32).copy()\n",
    "\n",
    "        # index for loading larger than window size\n",
    "        start_index = 0\n",
    "        if length > window_size and not self.only_start:\n",
    "            # randomly select window size subset instead of trying to cram in everything\n",
    "            start_index = np.random.randint(length - window_size)\n",
    "\n",
    "        self.f[f\"{user_id}/content_ids\"].read_direct(\n",
    "            content_ids,\n",
    "            source_sel=np.s_[start_index : start_index + window_size],\n",
    "            dest_sel=np.s_[0:window_size],\n",
    "        )\n",
    "        self.f[f\"{user_id}/answered_correctly\"].read_direct(\n",
    "            answered_correctly,\n",
    "            source_sel=np.s_[start_index : start_index + window_size],\n",
    "            dest_sel=np.s_[0:window_size],\n",
    "        )\n",
    "        self.f[f\"{user_id}/timestamps\"].read_direct(\n",
    "            timestamps,\n",
    "            source_sel=np.s_[start_index : start_index + window_size],\n",
    "            dest_sel=np.s_[0:window_size],\n",
    "        )\n",
    "\n",
    "        # convert timestamps to time elapsed\n",
    "        time_elapsed_timestamps = get_time_elapsed_from_timestamp(timestamps)\n",
    "\n",
    "        # get question tags\n",
    "        tags = questions_lectures_tags[content_ids, :]\n",
    "\n",
    "        # get question parts\n",
    "        parts = questions_lectures_parts[content_ids]\n",
    "\n",
    "        # shift by one the answered_correctly sequence\n",
    "        answers = np.roll(answered_correctly, 1)\n",
    "\n",
    "        # set start token if start_index is actually first element\n",
    "        if start_index == 0:\n",
    "            answers[0] = 2\n",
    "        # else replace first element of sequence with actual previous element\n",
    "        else:\n",
    "            self.f[f\"{user_id}/answered_correctly\"].read_direct(\n",
    "                answers, source_sel=np.s_[start_index - 1], dest_sel=np.s_[0],\n",
    "            )\n",
    "\n",
    "        return {\n",
    "            \"parts\": torch.from_numpy(parts).long(),\n",
    "            \"tags\": torch.from_numpy(tags).long(),\n",
    "            \"content_ids\": torch.from_numpy(content_ids),\n",
    "            \"answered_correctly\": torch.from_numpy(answered_correctly),\n",
    "            \"answers\": torch.from_numpy(answers),\n",
    "            \"timestamps\": torch.from_numpy(time_elapsed_timestamps),\n",
    "            \"length\": window_size,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "# The collate function is used to merge individual data samples into a batch\n",
    "# It handles the padding aspect\n",
    "def collate_fn(batch):\n",
    "    # collate lenghts into 1D tensor\n",
    "    items = {\"length\": torch.tensor([batch_item[\"length\"] for batch_item in batch])}\n",
    "\n",
    "    # find shape that the batch will have\n",
    "    max_length = items[\"length\"].max()\n",
    "    num_items = len(batch)\n",
    "\n",
    "    # padding list\n",
    "    for (key, padding) in [\n",
    "        (\"parts\", 0),\n",
    "        (\"content_ids\", 13942),\n",
    "        (\"answered_correctly\", 3),\n",
    "        (\"answers\", 3),\n",
    "        (\"timestamps\", 0.0),  # note timestamps isnt an embedding\n",
    "        (\"tags\", 188),\n",
    "    ]:\n",
    "        items[key] = pad_sequence(\n",
    "            [batch_item[key] for batch_item in batch],\n",
    "            batch_first=False,\n",
    "            padding_value=padding,\n",
    "        )\n",
    "\n",
    "    # mask to weight loss by (S, N)\n",
    "    items[\"loss_mask\"] = (\n",
    "        (\n",
    "            torch.arange(max_length).expand(num_items, max_length)\n",
    "            < items[\"length\"].unsqueeze(1)\n",
    "        )\n",
    "        .transpose(1, 0)\n",
    "        .float()\n",
    "    )\n",
    "    items[\"loss_mask\"] *= items[\"answered_correctly\"] != 4  # mask the lectures\n",
    "    items[\"answered_correctly\"] = items[\"answered_correctly\"].float()\n",
    "\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 855 ms, sys: 218 ms, total: 1.07 s\n",
      "Wall time: 1.07 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "338170"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Create Dataset will all users\n",
    "user_weights = train.groupby(\"user_id\").row_id.count().clip(upper=500)\n",
    "dataset = RIIDDataset(\n",
    "    user_weights.index.values,\n",
    "    hdf5_file=\"feats_train.h5\",\n",
    "    window_size=WINDOW_SIZE,\n",
    "    only_start=False,\n",
    ")\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.core.decorators import auto_move_data\n",
    "from pytorch_lightning.metrics.functional.classification import auroc\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, sequence_length):\n",
    "        # returns embeds (sequence_length, 1, d_model)\n",
    "        return self.pe[:sequence_length, :]\n",
    "\n",
    "\n",
    "class RIIDDTransformerModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate=0.001,\n",
    "        n_content_id=13943,  # number of different contents = 13942 + 1 (for padding)\n",
    "        n_part=8,  # number of different parts = 7 + 1 (for padding)\n",
    "        n_tags=189,  # number of different tags = 188 + 1 (for padding)\n",
    "        n_correct=5,  # 0,1 (false, true), 2 (start token), 3 (padding), 4 (lecture)\n",
    "        emb_dim=64,  # embedding dimension\n",
    "        dropout=0.1,\n",
    "        n_heads: int = 1,\n",
    "        n_encoder_layers: int = 2,\n",
    "        n_decoder_layers: int = 2,\n",
    "        dim_feedforward: int = 256,\n",
    "        activation: str = \"relu\",\n",
    "        batch_size=256,  # will get saved as hyperparam\n",
    "        num_user_train=300000,  # will get saved as hyperparam\n",
    "        num_user_val=30000,  # will get saved as hyperparam\n",
    "        max_window_size=100,\n",
    "    ):\n",
    "        super(RIIDDTransformerModel, self).__init__()\n",
    "        self.model_type = \"RiiidTransformer\"\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_window_size = max_window_size\n",
    "\n",
    "        # save params of models to yml\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.embed_content_id = nn.Embedding(n_content_id, emb_dim, padding_idx=13942)\n",
    "        self.embed_parts = nn.Embedding(n_part, emb_dim, padding_idx=0)\n",
    "        self.embed_tags = nn.Embedding(n_tags, emb_dim, padding_idx=188)\n",
    "        # exercise weights to weight the mean embeded excercise embeddings\n",
    "        self.exercise_weights = torch.nn.Parameter(torch.tensor([0.35, 0.55, 0.1]))\n",
    "\n",
    "        self.embed_answered_correctly = nn.Embedding(\n",
    "            n_correct, emb_dim, padding_idx=3\n",
    "        )  # 2 + 1 for start token + 1 for padding_idn_inputs\n",
    "\n",
    "        self.embed_timestamps = nn.Linear(1, emb_dim)\n",
    "\n",
    "        self.pos_encoder = PositionalEncoding(emb_dim)\n",
    "\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=emb_dim,\n",
    "            nhead=n_heads,\n",
    "            num_encoder_layers=n_encoder_layers,\n",
    "            num_decoder_layers=n_decoder_layers,\n",
    "            dropout=dropout,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            activation=activation,\n",
    "        )\n",
    "\n",
    "        self.out_linear = nn.Linear(emb_dim, 2)\n",
    "        init_weights(self)\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = (\n",
    "            mask.float()\n",
    "            .masked_fill(mask == 0, float(\"-inf\"))\n",
    "            .masked_fill(mask == 1, float(0.0))\n",
    "        )\n",
    "        return mask\n",
    "\n",
    "    def get_random_steps(self, lengths, max_steps=10):\n",
    "        \"\"\"\n",
    "        for a length x \n",
    "            if x >= 10:\n",
    "                returns a random integer between 1 - 10\n",
    "            else:\n",
    "                returns a random integer between 1 - x\n",
    "        \"\"\"\n",
    "        m = torch.distributions.uniform.Uniform(\n",
    "            0,\n",
    "            (\n",
    "                torch.minimum(\n",
    "                    torch.ones(lengths.shape, device=self.device) * 10, lengths\n",
    "                )\n",
    "            ).float(),\n",
    "        )\n",
    "        return torch.floor(m.sample()).long() + 1\n",
    "    \n",
    "    def get_random_lengths(self, lengths):\n",
    "        # gets random new lengths\n",
    "        m = torch.distributions.uniform.Uniform(0, lengths.float())\n",
    "        return torch.floor(m.sample()).long() + 1\n",
    "    \n",
    "    def randomize_evaluation_step(self, batch, max_steps=10):\n",
    "        # randomize new lengths (for where start token is present)\n",
    "        batch[\"length\"] = torch.where(\n",
    "            batch[\"answers\"][0, :] == 2,\n",
    "            self.get_random_lengths(batch[\"length\"]),\n",
    "            batch[\"length\"],\n",
    "        )\n",
    "        # randomize number of steps based on new random lengths\n",
    "        batch[\"steps\"] = self.get_random_steps(batch[\"length\"], max_steps=max_steps)\n",
    "        return batch\n",
    "\n",
    "    @auto_move_data\n",
    "    def forward(self, content_ids, parts, answers, tags, timestamps):\n",
    "        # content_ids: (Source Sequence Length, Number of samples, Embedding)\n",
    "        # tgt: (Target Sequence Length,Number of samples, Embedding)\n",
    "\n",
    "        # if data is flat then expand to get Batch dim\n",
    "        if len(content_ids.shape) == 1:\n",
    "            content_ids = content_ids.unsqueeze(1)\n",
    "            parts = parts.unsqueeze(1)\n",
    "            answers = answers.unsqueeze(1)\n",
    "            tags = tags.unsqueeze(1)\n",
    "            timestamps = timestamps.unsqueeze(1)\n",
    "\n",
    "        sequence_length = content_ids.shape[0]\n",
    "\n",
    "        # sequence that will go into encoder\n",
    "        embeded_content = self.embed_content_id(content_ids)\n",
    "        embeded_parts = self.embed_parts(parts)\n",
    "        embeded_tags = self.embed_tags(tags).sum(dim=2)\n",
    "        e_w = F.softmax(self.exercise_weights, dim=0)\n",
    "\n",
    "        embeded_exercise_sequence = (\n",
    "            (embeded_content * e_w[0])\n",
    "            + (embeded_parts * e_w[1])\n",
    "            + (embeded_tags * e_w[2])\n",
    "        )\n",
    "\n",
    "        # sequence that will go into decoder\n",
    "        embeded_responses = self.embed_answered_correctly(answers)\n",
    "        embeded_timestamps = self.embed_timestamps(timestamps.unsqueeze(2))\n",
    "        embeded_responses = (embeded_responses + embeded_timestamps) * 0.5\n",
    "\n",
    "        # adding positional vector\n",
    "        embedded_positions = self.pos_encoder(sequence_length)\n",
    "        embeded_responses = embeded_responses + embedded_positions\n",
    "        embeded_exercise_sequence = embeded_exercise_sequence + embedded_positions\n",
    "\n",
    "        # mask of shape S x S -> prevents attention looking forward\n",
    "        top_right_attention_mask = self.generate_square_subsequent_mask(\n",
    "            sequence_length\n",
    "        ).type_as(embeded_exercise_sequence)\n",
    "\n",
    "        output = self.transformer(\n",
    "            embeded_exercise_sequence,\n",
    "            embeded_responses,\n",
    "            tgt_mask=top_right_attention_mask,  # (S,S)\n",
    "            src_mask=top_right_attention_mask,  # (T,T)\n",
    "        )\n",
    "\n",
    "        output = self.out_linear(output)\n",
    "        return F.softmax(output, dim=2)[:, :, 1]\n",
    "\n",
    "    def process_batch_step(self, batch):\n",
    "        # return result\n",
    "        return self(\n",
    "            batch[\"content_ids\"],\n",
    "            batch[\"parts\"],\n",
    "            batch[\"answers\"],\n",
    "            batch[\"tags\"],\n",
    "            batch[\"timestamps\"],\n",
    "        )\n",
    "\n",
    "    @auto_move_data\n",
    "    def predict_n_steps(self, batch, steps, return_all_preds=False):\n",
    "        \"\"\"\n",
    "        Predicts n steps for all items in batch and return predictions\n",
    "        only for those steps (flattened)\n",
    "        steps: tensor of length B where each item is the number of steps that need to be taken\n",
    "        \"\"\"\n",
    "        n_users = batch[\"content_ids\"].shape[1]\n",
    "        lengths = batch[\"length\"]\n",
    "\n",
    "        users = torch.arange(n_users)\n",
    "\n",
    "        user_indexes = []\n",
    "        sequence_indexes = []\n",
    "\n",
    "        for i in range(steps.max().int(), 0, -1):\n",
    "            preds = model.process_batch_step(batch)\n",
    "\n",
    "            sequence_indexes_at_i = lengths[steps >= i] - i\n",
    "            user_indexes_at_i = users[steps >= i]\n",
    "\n",
    "            # set answer to either 0 or 1 if not lecture\n",
    "            batch[\"answers\"][sequence_indexes_at_i, user_indexes_at_i] = torch.where(\n",
    "                batch[\"answers\"][sequence_indexes_at_i, user_indexes_at_i] != 4,\n",
    "                (preds[sequence_indexes_at_i, user_indexes_at_i] > 0.5).long(),\n",
    "                4,\n",
    "            )\n",
    "\n",
    "            user_indexes.append(user_indexes_at_i)\n",
    "            sequence_indexes.append(sequence_indexes_at_i)\n",
    "\n",
    "        if return_all_preds:\n",
    "            return preds\n",
    "\n",
    "        user_indexes = torch.cat(user_indexes)\n",
    "        sequence_indexes = torch.cat(sequence_indexes)\n",
    "\n",
    "        return (\n",
    "            preds[sequence_indexes, user_indexes],\n",
    "            batch[\"row_ids\"][sequence_indexes, user_indexes],\n",
    "        )\n",
    "    \n",
    "    @auto_move_data\n",
    "    def predict_fast_single_user(\n",
    "        self, content_ids, parts, answers, tags, timestamps, n=1\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Predicts n steps for a single user in batch and return predictions\n",
    "        only for those steps (flattened)\n",
    "        \"\"\"\n",
    "        length = len(content_ids)\n",
    "        out_predictions = torch.zeros(n, device=self.device)\n",
    "        for i in range(n, 0, -1):\n",
    "            preds = self(content_ids, parts, answers, tags, timestamps)\n",
    "            out_predictions[n - i] = preds[length - i, 0]\n",
    "            answers[length - i] = torch.where(\n",
    "                answers[length - i] != 4, (preds[length - i, 0] > 0.5).long(), 4,\n",
    "            )\n",
    "        return out_predictions\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        result = self.process_batch_step(batch)\n",
    "        loss = F.binary_cross_entropy(\n",
    "            result, batch[\"answered_correctly\"], weight=batch[\"loss_mask\"]\n",
    "        )\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validate_n_steps(self, batch, max_steps=10):\n",
    "        \"\"\"\n",
    "        Predicts max_steps steps for all items in batch and return predictions\n",
    "        only for those steps (flattened)\n",
    "        steps: tensor of length B where each item is the number of steps that need to be taken\n",
    "        \"\"\"\n",
    "        n_users = batch[\"content_ids\"].shape[1]\n",
    "        lengths = batch[\"length\"]\n",
    "        steps = batch[\"steps\"]\n",
    "        users = torch.arange(n_users)\n",
    "        user_indexes = []\n",
    "        sequence_indexes = []\n",
    "        for i in range(steps.max().int(), 0, -1):\n",
    "            preds = model.process_batch_step(batch)\n",
    "            sequence_indexes_at_i = lengths[steps >= i] - i\n",
    "            user_indexes_at_i = users[steps >= i]\n",
    "            # set answer to either 0 or 1 if not lecture\n",
    "            batch[\"answers\"][sequence_indexes_at_i, user_indexes_at_i] = torch.where(\n",
    "                batch[\"answers\"][sequence_indexes_at_i, user_indexes_at_i] != 4,\n",
    "                (preds[sequence_indexes_at_i, user_indexes_at_i] > 0.5).long(),\n",
    "                4,\n",
    "            )\n",
    "            user_indexes.append(user_indexes_at_i)\n",
    "            sequence_indexes.append(sequence_indexes_at_i)\n",
    "\n",
    "        user_indexes = torch.cat(user_indexes)\n",
    "        sequence_indexes = torch.cat(sequence_indexes)\n",
    "        return (preds, sequence_indexes, user_indexes)\n",
    "\n",
    "    def val_test_step(self, batch, log_as=\"val\"):\n",
    "        batch = self.randomize_evaluation_step(batch)\n",
    "        \n",
    "        result, sequence_indexes, user_indexes = self.validate_n_steps(batch)\n",
    "        \n",
    "        step_mask = torch.zeros(batch[\"loss_mask\"].shape, device=self.device)\n",
    "        step_mask[sequence_indexes, user_indexes] = 1\n",
    "\n",
    "        batch[\"loss_mask\"] *= step_mask\n",
    "\n",
    "        loss = F.binary_cross_entropy(\n",
    "            result, batch[\"answered_correctly\"], weight=batch[\"loss_mask\"]\n",
    "        )\n",
    "        self.log(f\"{log_as}_loss_step\", loss)\n",
    "        select_mask = batch[\"loss_mask\"] > 0\n",
    "        positions = torch.cat(\n",
    "            result.shape[1] * [torch.arange(result.shape[0]).unsqueeze(1)], dim=1\n",
    "        )\n",
    "        return (\n",
    "            torch.masked_select(result, batch[\"loss_mask\"] > 0),\n",
    "            torch.masked_select(batch[\"answered_correctly\"], batch[\"loss_mask\"] > 0),\n",
    "            torch.masked_select(positions, select_mask),\n",
    "        )\n",
    "\n",
    "    def val_test_epoch_end(self, outputs, log_as=\"val\"):\n",
    "        y_pred = torch.cat([out[0] for out in outputs], dim=0)\n",
    "        y = torch.cat([out[1] for out in outputs], dim=0)\n",
    "        pos = torch.cat([out[2] for out in outputs], dim=0)\n",
    "        auc = auroc(y_pred, y)\n",
    "\n",
    "\n",
    "        # Calculate accuracy per position\n",
    "        M = torch.zeros(pos.max() + 1, len(y), device=self.device)\n",
    "        M[pos, torch.arange(len(y))] = 1\n",
    "        M = torch.nn.functional.normalize(M, p=1, dim=1)\n",
    "        acc_per_position = torch.mm(\n",
    "            M, ((y_pred > 0.5) == y).float().unsqueeze(1)\n",
    "        ).flatten()\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        sns.regplot(\n",
    "            y=acc_per_position.cpu(), x=torch.arange(len(acc_per_position)).cpu(), ax=ax\n",
    "        )\n",
    "        ax.set_ylim(0.5, 1)\n",
    "        ax.set_xlim(0, len(acc_per_position) - 1)\n",
    "        ax.set_ylabel(\"acc\")\n",
    "        ax.set_xlabel(\"position\")\n",
    "        if log_as == \"val\":\n",
    "            self.log(f\"avg_{log_as}_auc\", auc, prog_bar=True)\n",
    "            self.logger.experiment.add_figure(\n",
    "                f\"{log_as}_acc_per_pos\", fig, global_step=self.current_epoch\n",
    "            )\n",
    "        else:\n",
    "            self.log(f\"avg_{log_as}_auc\", auc)\n",
    "            self.logger.experiment.add_figure(\n",
    "                f\"{log_as}_acc_per_pos\", fig, global_step=1\n",
    "            )\n",
    "\n",
    "    def validation_step(self, batch, batch_nb, dataset_nb=None):\n",
    "        return self.val_test_step(batch, log_as=\"val\")\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        self.val_test_epoch_end(outputs, log_as=\"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_nb, dataset_nb=None):\n",
    "        return self.val_test_step(batch, log_as=\"test\")\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        self.val_test_epoch_end(outputs, log_as=\"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        scheduler = {\n",
    "            \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer, mode=\"max\", patience=10\n",
    "            ),\n",
    "            \"monitor\": \"avg_val_auc\",\n",
    "            \"interval\": \"epoch\",\n",
    "            \"frequency\": 1,\n",
    "            \"strict\": True,\n",
    "        }\n",
    "\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                     | Type               | Params\n",
      "----------------------------------------------------------------\n",
      "0 | embed_content_id         | Embedding          | 892 K \n",
      "1 | embed_parts              | Embedding          | 512   \n",
      "2 | embed_tags               | Embedding          | 12.1 K\n",
      "3 | embed_answered_correctly | Embedding          | 320   \n",
      "4 | embed_timestamps         | Linear             | 128   \n",
      "5 | pos_encoder              | PositionalEncoding | 0     \n",
      "6 | transformer              | Transformer        | 233 K \n",
      "7 | out_linear               | Linear             | 130   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e471d34454a443dfa727acba97351225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01dc6ad87fc942b79b4c47bd22340f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gautier/miniconda3/envs/kaggle/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    ")\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "seed_everything(SEED)\n",
    "\n",
    "\n",
    "# Params\n",
    "learning_rate = 0.001  # 0.0001\n",
    "emb_dim = 64  # 256\n",
    "dropout = 0.0\n",
    "n_heads = 2  # 2\n",
    "n_encoder_layers = 2\n",
    "n_decoder_layers = 2\n",
    "dim_feedforward = 256\n",
    "batch_size = 256\n",
    "num_user_train = 300000\n",
    "num_user_val = 30000\n",
    "max_window_size = WINDOW_SIZE\n",
    "\n",
    "\n",
    "# create split\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset,\n",
    "    [num_user_train, num_user_val, len(dataset) - num_user_train - num_user_val,],\n",
    ")\n",
    "\n",
    "# Init DataLoader from RIIID Dataset subset\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    #     shuffle=True,\n",
    "    # Weighted sampler\n",
    "    sampler=torch.utils.data.WeightedRandomSampler(\n",
    "        weights=user_weights.values[train_dataset.indices],\n",
    "        num_samples=len(train_dataset),\n",
    "    ),\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=6,\n",
    "    pin_memory=torch.cuda.is_available(),  # if GPU then pin memory for perf\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=512,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=6,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "for n_heads in [2, 4]:\n",
    "    # Init our model\n",
    "    model = RIIDDTransformerModel(\n",
    "        learning_rate=learning_rate,\n",
    "        emb_dim=emb_dim,  # embedding dimension - this is for everything\n",
    "        dropout=dropout,\n",
    "        n_heads=n_heads,\n",
    "        n_encoder_layers=n_encoder_layers,\n",
    "        n_decoder_layers=n_decoder_layers,\n",
    "        dim_feedforward=dim_feedforward,\n",
    "        batch_size=batch_size,\n",
    "        num_user_train=num_user_train,\n",
    "        num_user_val=num_user_val,\n",
    "        max_window_size=max_window_size,\n",
    "    )\n",
    "\n",
    "    logger = TensorBoardLogger(\"lightning_logs\", name=f\"weighted_sampling_h_{n_heads}\",)\n",
    "\n",
    "    # Initialize a trainer\n",
    "    trainer = pl.Trainer(\n",
    "        gpus=1,\n",
    "        max_epochs=500,\n",
    "        progress_bar_refresh_rate=1,\n",
    "        callbacks=[\n",
    "            EarlyStopping(monitor=\"avg_val_auc\", patience=20, mode=\"max\"),\n",
    "            ModelCheckpoint(\n",
    "                monitor=\"avg_val_auc\",\n",
    "                filename=\"{epoch}-{val_loss_step:.2f}-{avg_val_auc:.2f}\",\n",
    "                mode=\"max\",\n",
    "            ),\n",
    "            LearningRateMonitor(logging_interval=\"step\"),\n",
    "        ],\n",
    "        logger=logger,\n",
    "    )\n",
    "\n",
    "    # Train the model ⚡\n",
    "    trainer.fit(\n",
    "        model, train_dataloader=train_loader, val_dataloaders=[val_loader],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a0925b900e4f1880b7de1da67a9054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'avg_test_auc': tensor(0.8071, device='cuda:0'),\n",
      " 'avg_val_auc': tensor(0.8057, device='cuda:0'),\n",
      " 'test_loss_step': tensor(0.0260, device='cuda:0'),\n",
      " 'train_loss': tensor(0.4529, device='cuda:0'),\n",
      " 'val_loss_step': tensor(0.0256, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'train_loss': 0.45292365550994873,\n",
       "  'avg_val_auc': 0.8056510090827942,\n",
       "  'val_loss_step': 0.0256417915225029,\n",
       "  'avg_test_auc': 0.8071117997169495,\n",
       "  'test_loss_step': 0.02599533088505268}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load best\n",
    "model = RIIDDTransformerModel.load_from_checkpoint(\n",
    "    \"lightning_logs/weighted_sampling_h_4/version_0/checkpoints/epoch=38-val_loss_step=0.03-avg_val_auc=0.81.ckpt\"\n",
    ")\n",
    "\n",
    "model.freeze()\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=512,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=6,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "trainer.test(\n",
    "    model=model, test_dataloaders=test_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate Kaggle Sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceRIIDDataset(Dataset):\n",
    "    \"\"\"RIID dataset.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, hdf5_file=\"feats.h5\", window_size=100,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            user_mapping (np.array): array of all unique user ids \n",
    "            hdf5_file (string): location of hf5 feats file\n",
    "        \"\"\"\n",
    "        self.hdf5_file = hdf5_file\n",
    "        self.max_window_size = window_size\n",
    "        self.cache = {}\n",
    "\n",
    "    def open_hdf5(self):\n",
    "        # opens the h5py file\n",
    "        self.f = h5py.File(self.hdf5_file, \"r\")\n",
    "\n",
    "    def __len__(self):\n",
    "        if not hasattr(self, \"f\"):\n",
    "            self.open_hdf5()\n",
    "        return len(self.f.keys())\n",
    "\n",
    "    def load_user_into_cache(self, user_id):\n",
    "        \"\"\"\n",
    "        add a user to self.cache\n",
    "        \"\"\"\n",
    "\n",
    "        if not hasattr(self, \"f\"):\n",
    "            self.open_hdf5()\n",
    "\n",
    "        if f\"{user_id}\" in self.f:\n",
    "            content_ids = self.f[f\"{user_id}/content_ids\"]\n",
    "            answers = self.f[f\"{user_id}/answered_correctly\"]\n",
    "            timestamps = self.f[f\"{user_id}/timestamps\"]\n",
    "\n",
    "            self.cache[user_id] = {\n",
    "                \"content_ids\": content_ids,\n",
    "                \"answers\": answers,\n",
    "                \"timestamps\": timestamps,\n",
    "                \"row_ids\": np.zeros(len(timestamps)),\n",
    "                \"steps\": 0,\n",
    "            }\n",
    "        else:\n",
    "            self.cache[user_id] = {\n",
    "                \"content_ids\": np.array([], dtype=\"int64\"),\n",
    "                \"timestamps\": np.array([], dtype=\"float32\"),\n",
    "                \"answers\": np.array([], dtype=\"int64\"),\n",
    "                \"row_ids\": np.array([], dtype=\"int64\"),\n",
    "                \"steps\": 0,\n",
    "            }\n",
    "\n",
    "    def update_user_rows(self, user_rows):\n",
    "        if not hasattr(self, \"f\"):\n",
    "            self.open_hdf5()\n",
    "\n",
    "        user_id = user_rows.user_id.values[0]\n",
    "        num_rows = len(user_rows)\n",
    "        new_content_ids = user_rows.content_id.values\n",
    "        new_timestamps = user_rows.timestamp.values\n",
    "        new_answered_correctly = (\n",
    "            user_rows.answered_correctly.values\n",
    "        )  # should be 3 (3) for every question and 4 for lectures\n",
    "        new_row_ids = user_rows.row_id.values\n",
    "\n",
    "        if user_id not in self.cache:\n",
    "            self.load_user_into_cache(user_id)\n",
    "\n",
    "        self.cache[user_id][\"content_ids\"] = np.concatenate(\n",
    "            [self.cache[user_id][\"content_ids\"], new_content_ids]\n",
    "        )[-(self.max_window_size + 1) :]\n",
    "\n",
    "        self.cache[user_id][\"timestamps\"] = np.concatenate(\n",
    "            [self.cache[user_id][\"timestamps\"], new_timestamps]\n",
    "        )[-(self.max_window_size + 1) :]\n",
    "\n",
    "        self.cache[user_id][\"answers\"] = np.concatenate(\n",
    "            [self.cache[user_id][\"answers\"], new_answered_correctly]\n",
    "        )[-(self.max_window_size + 1) :]\n",
    "\n",
    "        self.cache[user_id][\"row_ids\"] = np.concatenate(\n",
    "            [self.cache[user_id][\"row_ids\"], new_row_ids]\n",
    "        )[-(self.max_window_size + 1) :]\n",
    "\n",
    "        self.cache[user_id][\"steps\"] = len(new_row_ids)\n",
    "\n",
    "    def update_answered_correctly(self, answered_correctly_rows):\n",
    "        user_id = answered_correctly_rows.name\n",
    "        new_answered_correctly = (\n",
    "            answered_correctly_rows.values\n",
    "        )  # this is only the answers\n",
    "        \n",
    "        # update the correct answers for the questions (keep 4 - lectures)\n",
    "        self.cache[user_id][\"answers\"][-len(new_answered_correctly) :] = np.where(\n",
    "            self.cache[user_id][\"answers\"][-len(new_answered_correctly) :] != 4,\n",
    "            new_answered_correctly,\n",
    "            4,\n",
    "        )\n",
    "        self.cache[user_id][\"steps\"] = 0\n",
    "\n",
    "    def __getitem__(self, user_id):\n",
    "        if user_id not in self.cache:\n",
    "            self.load_user_into_cache(user_id)\n",
    "\n",
    "        length = len(self.cache[user_id][\"content_ids\"])\n",
    "        window_size = min(self.max_window_size, length)\n",
    "\n",
    "        content_ids = self.cache[user_id][\"content_ids\"][-window_size:]\n",
    "\n",
    "        answers = self.cache[user_id][\"answers\"][-window_size:]\n",
    "        timestamps = self.cache[user_id][\"timestamps\"][-window_size:]\n",
    "        row_ids = self.cache[user_id][\"row_ids\"][-window_size:]\n",
    "\n",
    "        # convert timestamps to time elapsed\n",
    "        time_elapsed_timestamps = get_time_elapsed_from_timestamp(timestamps)\n",
    "\n",
    "        # get tags\n",
    "        tags = questions_lectures_tags[content_ids, :].astype(np.int64)\n",
    "\n",
    "        # get parts\n",
    "        parts = questions_lectures_parts[content_ids].astype(np.int64)\n",
    "\n",
    "        # shift by one the answered_correctly sequence\n",
    "        answers = np.roll(answers, 1)\n",
    "\n",
    "        if length > self.max_window_size:\n",
    "            answers[0] = self.cache[user_id][\"answers\"][-window_size - 1]\n",
    "        else:\n",
    "            answers[0] = 2\n",
    "\n",
    "        return {\n",
    "            \"parts\": torch.from_numpy(parts).long(),\n",
    "            \"tags\": torch.from_numpy(tags).long(),\n",
    "            \"content_ids\": torch.from_numpy(content_ids).long(),\n",
    "            \"answers\": torch.from_numpy(answers).long(),\n",
    "            \"timestamps\": torch.from_numpy(time_elapsed_timestamps).float(),\n",
    "            \"length\": window_size,\n",
    "            \"row_ids\": torch.from_numpy(row_ids).int(),\n",
    "            \"steps\": self.cache[user_id][\"steps\"],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "# The collate function is used to merge individual data samples into a batch\n",
    "# It handles the padding aspect\n",
    "def inference_collate_fn(batch):\n",
    "    # collate lenghts into 1D tensor\n",
    "    items = {\n",
    "        \"length\": torch.tensor([batch_item[\"length\"] for batch_item in batch]),\n",
    "        \"steps\": torch.tensor([batch_item[\"steps\"] for batch_item in batch]),\n",
    "    }\n",
    "\n",
    "    # find shape that the batch will have\n",
    "    max_length = items[\"length\"].max()\n",
    "    num_items = len(batch)\n",
    "    if num_items > 1:\n",
    "        # padding list\n",
    "        for (key, padding) in [\n",
    "            (\"parts\", 0),\n",
    "            (\"content_ids\", 13942),\n",
    "            (\"answers\", 3),\n",
    "            (\"timestamps\", 0.0),  # note timestamps isnt an embedding\n",
    "            (\"tags\", 188),\n",
    "            (\"row_ids\", 0),\n",
    "        ]:\n",
    "            items[key] = pad_sequence(\n",
    "                [batch_item[key] for batch_item in batch],\n",
    "                batch_first=False,\n",
    "                padding_value=padding,\n",
    "            )\n",
    "    else:\n",
    "        for key in [\"parts\", \"content_ids\", \"answers\", \"timestamps\", \"tags\", \"row_ids\"]:\n",
    "            items[key] = batch[0][key].unsqueeze(1)\n",
    "    return items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict for DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# model = RIIDDTransformerModel.load_from_checkpoint(\n",
    "#     \"lightning_logs/lecture_model/version_10/checkpoints/epoch=69-val_loss_step=0.03-avg_val_auc=0.79.ckpt\"\n",
    "# )\n",
    "model.freeze()\n",
    "model.cuda()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 2s, sys: 1.14 ms, total: 1min 2s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "valid_groups = np.array_split(valid, len(valid) // 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33057c15b8343bf9a68c3f1dd4dc11a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=250000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inference_dataset = InferenceRIIDDataset(hdf5_file=\"feats_train.h5\",)\n",
    "\n",
    "\n",
    "def predict_for_df(df):\n",
    "    # select questions only\n",
    "    unique_users_with_questions = df[~df.content_type_id].user_id.unique()\n",
    "    df[\"answered_correctly\"] = 0.5  # set useless value for column\n",
    "\n",
    "    # batch with only lectures\n",
    "    if len(unique_users_with_questions) < 1:\n",
    "        pass  # return empy\n",
    "\n",
    "    # case of single user with questions in batch\n",
    "    elif len(unique_users_with_questions) == 1:\n",
    "        item = inference_dataset[unique_users_with_questions[0]].copy()\n",
    "        predictions = model.predict_fast_single_user(\n",
    "            item[\"content_ids\"],\n",
    "            item[\"parts\"],\n",
    "            item[\"answers\"],\n",
    "            item[\"tags\"],\n",
    "            item[\"timestamps\"],\n",
    "            n=item[\"steps\"],\n",
    "        ).cpu()\n",
    "        df.loc[\n",
    "            df.user_id == unique_users_with_questions[0], \"answered_correctly\"\n",
    "        ] = predictions.numpy()\n",
    "    # case of multiple users with questions in batch\n",
    "    else:\n",
    "        batch = inference_collate_fn(\n",
    "            [inference_dataset[u].copy() for u in unique_users_with_questions]\n",
    "        )\n",
    "        predictions, row_ids = model.predict_n_steps(batch, batch[\"steps\"])\n",
    "        df[\"answered_correctly\"] = df[\"row_id\"].map(\n",
    "            dict(zip(row_ids.cpu().numpy(), predictions.cpu().numpy()))\n",
    "        )\n",
    "    return df[~df.content_type_id]\n",
    "\n",
    "\n",
    "previous_test_df = None\n",
    "predictions = []\n",
    "row_ids = []\n",
    "for current_test in tqdm(valid_groups):\n",
    "    if previous_test_df is not None:\n",
    "        previous_test_df[~previous_test_df.content_type_id].groupby(\n",
    "            \"user_id\"\n",
    "        ).answered_correctly.apply(inference_dataset.update_answered_correctly)\n",
    "    # add current to cache\n",
    "    current_test = current_test.copy()\n",
    "    previous_test_df = current_test.copy()\n",
    "    current_test.drop(columns=[\"answered_correctly\"], inplace=True)\n",
    "\n",
    "    # preprocessing code heree\n",
    "    current_test = preprocess_df(current_test)\n",
    "    current_test[\n",
    "        [\"row_id\", \"user_id\", \"content_id\", \"timestamp\", \"answered_correctly\"]\n",
    "    ].groupby(\"user_id\").apply(\n",
    "        lambda user_rows: inference_dataset.update_user_rows(user_rows)\n",
    "    )\n",
    "\n",
    "    # your prediction code here\n",
    "    current_test = predict_for_df(current_test)\n",
    "    predictions.append(current_test[\"answered_correctly\"].values)\n",
    "    row_ids.append(current_test[\"row_id\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = np.concatenate(predictions)\n",
    "all_row_ids = np.concatenate(row_ids)\n",
    "df = pd.DataFrame({\"predictions\": all_preds, \"row_id\": all_row_ids})\n",
    "df = df.merge(valid[[\"row_id\", \"user_id\", \"answered_correctly\"]], on=\"row_id\", how=\"left\")\n",
    "print('validation auc:',roc_auc_score(df.answered_correctly.values, df.predictions.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAy0AAAINCAYAAAAzy5CEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAByUElEQVR4nO3deXzU1b3/8ffMZIUQAllJQghCFIILLoBLUYs7Fmtd6vazaq9K0Wttr3trReu9ausV64LIVblWbbVqvVWKtr1XqDuiVaQa1IAESCALgQQCWWe+vz8mM8xkZpJMMjPf78y8no8HD8hsOXNm4fv+nnM+x9bS0mIIAAAAACzKbnYDAAAAAKA/hBYAAAAAlkZoAQAAAGBphBYAAAAAlkZoAQAAAGBphBYAAAAAlkZoAQAAAGBppoaW9957TxdeeKGmTp2qnJwc/e53vxvwPl988YXmzp2roqIiTZ06Vb/61a9kGGw1AwAAACQqU0PL3r17VVlZqfvuu0+ZmZkD3n737t363ve+p4KCAq1cuVL33XefHnnkET366KMxaC0AAAAAM6SY+ctPPfVUnXrqqZKka665ZsDbv/TSS2pvb9eSJUuUmZmpyspKff3113rsscf0r//6r7LZbNFuMgAAAIAYi6s1LWvWrNExxxzjNypz0kknafv27dq8ebOJLQMAAAAQLXEVWhobG5Wfn+93mefnxsZGM5oEAAAAIMriKrQAAAAASD5xFVoKCgrU1NTkd5nn54KCAjOahBCqq6vNbkLSou/NQ9+bi/43D31vHvrePPR9bMVVaJk5c6Y++OADdXR0eC9btWqVxo0bpwkTJpjYMgAAAADRYmpoaWtr07p167Ru3Tq5XC7V1tZq3bp12rp1qyTprrvu0llnneW9/XnnnafMzExdc801qqqq0muvvabf/OY3uuaaa6gcBgAAACQoU0PLp59+quOPP17HH3+82tvbde+99+r444/XPffcI0mqr6/Xpk2bvLcfPXq0/ud//kfbt2/Xt7/9bd1000269tpr9a//+q9mPQUAAAAAUWbqPi2zZ89WS0tLyOuXLFkScNm0adP0xhtvRLFVAAAAAKwkrta0AAAAAEg+hBYAAAAAlkZoAQAAAGBphBYAAAAAlkZoAQAAAGBphBYAAAAAlkZoAQAAAGBphBYAAAAAlkZoAQAAAGBphBYAAAAAlkZoAQAAAGBphBYAAAAAlkZoAQAAAGBphBYAAAAAlkZoAQAAAGBphBYAAAAAlkZoAQAAAGBphBYAAAAAlkZoAQAAAGBphBYAAAAAlkZoAQAAAGBphBYAAAAAlkZoAQAAAGBphBYAAAAAlkZoAQAAAGBphBYAAAAAlkZoAQAAAGBphBYAAAAAlkZoAQAAAGBphBYAAAAgySyvadfc15u0vKbd7KYMCqEFAAAASDJLqtq0cXePHq9qM7spg0JoAQAAAJLMgsosTc5O0Y8qs8xuyqCkmN0AAAAAALE1rzxT88ozzW7GoDHSAgAAAMDSCC0AAAAALI3QAgAAAMDSCC0AAACIuv5K7MZb+V3EHqEFAAAAUddfid14K7+L2CO0AAAAIOr6K7Ebb+V3EXuUPAYAAEDU9VdiN97K7yL2GGkBAAAAYGmEFgAAAACWRmgBACBJLa9p16xX6nX0Kw1UbQJgaYQWAACS1JKqNn2z20nVJgCWR2gBAJiCfRnMt6AyS5OyHZpE1SYAFkf1MACAKXz3ZaBqkDmo2AQgXjDSAgAwBfsyAAAGi5EWAIApOMsPABgsRloAAAAAWBqhBQAAAIClEVoAAAAAWBqhBQAAAIClEVoAAAAAWBqhBQAAAIClEVoAAAAAWBqhBQAAAIClEVoAAAAAWBqhBQAAAIClEVoAAAAAWBqhBQAAAIClEVoAAAAAWBqhBQAAAIClEVoAAAAAWBqhBQAAAIClEVoAAAAAWBqhBQAAAIClEVoAAAAAWBqhBQAQEctr2jX39SYtr2k3uykAgARDaAEARMSSqjZt3N2jx6vazG4KACDBEFoAABGxoDJLk7NT9KPKLLObAiAERkQRrwgtAICImFeeqRVz8zWvPNPspgAIwSojorEMT2YENcJh5BFaAAAAkoRVRkRjGZ7MCGpWCYeJhNACAACQJKwyIhrL8GRGULNKOEwkKWY3AAAAAMllXnlmzIJTLH+Xmb8z0THSAgAAAMDSCC0AAAAALI3QAgAAAMDSCC0AAAAALI3QAgAAAMDSCC0AAAAALI3QAgAAAMDSCC0AAAAALI3QAgAAAMDSTA8tTz75pA499FAVFhbqhBNO0Pvvv9/v7Z944gnNnDlTRUVFOuqoo/T888/HqKUAAAAAzGBqaHnllVd066236oYbbtDbb7+tmTNn6vzzz9fWrVuD3v6pp57SnXfeqZtvvlmrV6/WbbfdpptuuklvvPFGjFsOAAAAIFZMDS2LFy/WxRdfrMsuu0wHHXSQ7r//fhUWFmrZsmVBb/+HP/xBP/jBD3TeeeepvLxc5557ri677DI99NBDMW45AAAAgFhJMesXd3V1ae3atbruuuv8Lp8zZ44+/PDDoPfp7OxURkaG32WZmZn6xz/+oe7ubqWmpga9X3V1dWQajbDQ7+ah781D35uL/jcPfW8e+t489H1kVVRUhLzOtNDS3Nwsp9Op/Px8v8vz8/PV2NgY9D4nnXSSnn32Wc2bN0+HH3641q5dq2eeeUbd3d1qbm5WUVFR0Pv11wGIjurqavrdJPS9eeh7c9H/5qHvzUPfm4e+jy3TQstQ3HTTTWpoaNCpp54qwzBUUFCgiy66SA899JDsdtNrCgAAAACIAtOO9HNzc+VwONTU1OR3eVNTkwoKCoLeJzMzU4sXL9b27du1bt06ff755yorK9OoUaOUl5cXi2YDQMwsr2nX3NebtLym3eymAABgKtNCS1pamqZPn65Vq1b5Xb5q1SrNmjWr3/umpqaqpKREDodDf/zjH3Xaaacx0gIg4SypatPG3T16vKrN7KYAAGAqU6eHXXvttZo/f76OPPJIzZo1S8uWLVN9fb2uuOIKSdL8+fMlSUuXLpUkbdiwQR9//LFmzJihlpYWLV68WOvXr9eSJUtMew4AEC0LKrP0eFWbflSZZXZTAAAwlamh5ZxzztHOnTt1//33q6GhQVOnTtWLL76osrIySVJtba3f7Z1OpxYvXqwNGzYoNTVV3/rWt/S3v/1NEyZMMKP5ABBV88ozNa880+xmmGJ5TbuWVLVpQWVW0vYBAGA/0xfiX3nllbryyiuDXrdixQq/nw866CC98847sWgWAMBEvlPjCC0AABaCAAAsZ0FlliZnpzA1DhBFOQCJ0AIAsKB55ZlaMTefURZAFOUI11BDHuEwPIPpr0j2KaEFAADAwhh5DM9QQx7hMDyD6a9I9imhBQCAGOJsLsLFyGN4hhryCIfhGUx/RbJPTV+IDwBAMqHIABBdQ628mMwVG4diMP0VyT5lpAUAgBjibC4AhI+RFgAAYigWZ3PZ5wZAomGkBQCABMOCYgCJhtACAIhbybSoPZznyhQ0AImG0AIAiFvJNKIQznOl2hSARENoAQDErWQaUUim5woAfbEQHwAQt3wXtVdXR+5xrbiQnXKsAJIZIy0AAPSRTNPOACAeEFoAAOiDqVgAYC2EFgAA+mAhe2QlU5U3INL4/LgRWgAAQFQx3Q4YOj4/boQWAACGiTOh/WO6HTB0fH7cqB4GAMAw+Z4JZUpZICqfAUPH58eNkRYAAIYp3s6EMjIEIN4w0gIAwDDF25lQRoYAxBtGWgAASDLxNjIEAIy0AACQZOJtZAgAGGkBgDjBOgQAQLIitABAnKBWP5INQR2AB6EFAOIE6xCQbAjqADwILQAQJ+aVZ2rF3HzWIiCmzBztIKgD8GAhPgAACMnM8sgUDADgwUgLAAAIidGO/VhjA5iHkRYAABASox37sSknYB5GWgAAAAaBUSfAPIy0AAAADILvqNPymnYtqWrTgsosRl2AGGCkBQAQgLn7QP8oxwzEFqEFABCAAzKgf0wVA2KL6WEAgAALKrP0eFUbB2RACBQoAGKL0AIACJDMB2SsVQAA62F6GAAAPpgaBwDWQ2gBAERVvC3qt9pahXjrPwCIBkILACCq4m3kYl55plbMzfebGmZmcOiv/wg0AJIFoQUAEFVWG7kYCjODV3/9F2+BEACGitACAIiqviMX8Tg6YGbwCjbyY4V2AUAsUT0MABBTvqMD8VKdy6rV1KzaLgCINEZaAAAxlayjA/E4wgQAVkFoAQAMS7gH4/1Nd0pkrD8BgKEjtAAAhoWD8cFJ1hEmAIgE1rQAAIZlQWWWHq9q42B8AKw/AYChI7QAAIaFg3EAQLQxPQwAAACApRFaACCBUbEqfljltbJKOxJFMvVnMj1XxB6hBQASGIvkhyeWB2Fmv1ae5/ofn+zmPRNBZr+usZRMzxWxR2gBgATmqVh1VF4qZ0CHIJYHYYOtLhatIOV5rpJBlbMISqaqccn0XBF7LMQHgATmWSQ/9/WmuNuF3gpiWRltsAUNfINUJF9L3+fKeyRykqlQRTI9V8QeoQUAkgBliYfGigdh0XotrfhcAcCD0AIAFrC8pl1Lqtq0IEpnuTkgHVi0X4NI4bUEkIxY0wIAFsACVvPxGiCRJEolr0R5HmZJpP4jtACABbCA1Xy8BkgkiRLCE+V5mCWR+o/QAgAWMK88Uyvm5if0tB+rn/FLhtcAySNRQniiPA+zJFL/saYFiBPxMt8eCCVaVa8QG3wHxZdEWfuUKM/DLInUf4y0AHEikYZ4kZwS6YxfMuI7CICZCC1AnOCAD/GO6Vfxje+g4Kw+7RFIFEwPA+JEvA3xMpUESCzx9h0UK0x7BGKDkRYAUcFUEgDJgBEoIDYILUgoDNNbB/+RAxhIInxnM+0RiA1CCxIKZ/etg//I3QY6KEuEg7ZkYvXXK5bti8Tv4jsbwGARWpBQOLsPqxnooIyDtvhi9dcrlu2LxO/iOxvAYBFakFA4uw+rGeigLBIHbVY/+59IrH6QHcv2ReJ38Z3N5xcYLKqHAUmASl5DE4l+G6jiUiQqMkWyehHvlf5ZvYJWLNvn+7uqq2PyKxMS1ceAwUmOkRbDMLsFgKmsPqWlL6uceYyXfovk2fV4ec5WeY8Aw2X10TvAKpIitNi/+Ua2LVtka2yUWlqkjg6CDJJKvP2naJUD50j2WzQPsiM5xSZe3itWeY8Aw8UUOWBwkmN6mGHI1tUldXXJ5ntxWpqUni4jPV3KyJDS0yWbLeTDAPHK6lNa+lpQmaXHq9pMP3COZL/FyxSQeHmvWOU9AgCIjeQILSF4g8yePb0X2NxBJiNjf5BJSzO3kUASipcD53BwkB3cUNfQJOJ7BAAQWlKHlgCGIVtnp9TZuX9Exm4PDDKpqWa2EkAc4iA7uHgZgQIAmCsp1rQMi8slW0eHbC0tsjc0yL55s+ybNslWVyfbjh3S7t1SZydrZJAwWOAcG4ncz+E8t3hZQwMAMBehZSicTtna291BprFR9q1b9y/2b2hwL/bfu1fq6TG7pQkvkQ/8zMIC59hI5H4O57mxCDmxJdN3dDI9V8AMhJZI6V3sb9uzR/YdO2Tfvl32mhp3mKmt3V+5bN8+yek0u7XDYqUv5kQ+8DMLZ75jI5H7OZrPzUrfPxhYMn1HJ8Nz5fMXW/S3P9a0RFvv9DJ1dPhXLktJcS/yT0/3VjGLl0X/VpqDzuLmyGPtRWwkcj9H87lZ6fsHA0um7+hkeK58/mKL/vbHSItJbD09su3bJ9uuXe61Mlu2yL5xo2xbt+4flWlvl1wus5sawIwzxKHONjC1BFbDmbHoSuQRqkTi+RxISprv6GT4/8iKn79E/s61Yn+biZEWKwlWvUy9ozLp6ftHZTIypBTzXjozzhDH8mzDUEuwAhJnxqItEUeoEvE7h89BYrLi5y+R32tW7G8zMdISB2w9PbLt3Svbzp2y19e718ps2iTbtm2yNTdLbW1Sd7fZzYyqWJ5tSIZ5ybGWyGfC+uLMGMKViN85fA4QK7zXkgcjLfHK6ZRt3z5p3779ozIOh3d9jN86GZutv0eKC7E825AM85JjLZHPhPUVr2fGEvFsf7xIxO+ceP0cIP7wXkseSRFa7OvXy1VaKo0aZXZToqu3FLPa2/cHGZtNRmqqO8h4Qkx6uuRwmNlSS4vGF2CyHxAm4kFZokmmYGk1HHQBwMCSIrSMvPRSSZIxerRcJSVylZZ6/xiev/PyJHsCzpbrLcWs3nLMXgk8KmNFyX5AyEGZ9REsAQBWlhShxTlpkux1dbK1tsrR2ipHVVXAbYz0dLlKSmT0CTWu0lIZxcVSaqoJLY+iYKMykntUxjfMeP5gWIZyQJjsozOILYIlAMDKTA8tTz75pB5++GE1NDRoypQpuvfee3XssceGvP1LL72khx56SBs3btSoUaN04okn6u6771ZhYWHI++z7wx/cIw7NzbLX1spWWyu7zx9bba3sLS1yfPON9M03Afc37HYZhYX7Q4wn2Iwf7552NnJkRPrCCmzd3e5F/Xv3+k8x6w0vTDEbmqEcECb76AwAAICHqaHllVde0a233qoHHnhARx99tJ588kmdf/75Wr16tcaPHx9w+9WrV2v+/Pm6++67deaZZ6qpqUk33HCDrrrqKr322mv9/zKbTUZenpx5edL06YHXt7X5B5m6uv3/bmhw73C/fbv00UcBd3WNGeOdZuYqLXWP2HgCTm6uJaZcrazr0PMb9umiySM0pyQjvDv7lmLub4qZJ8xY4PkmAqbrAAAAuJkaWhYvXqyLL75Yl112mSTp/vvv15tvvqlly5Zp4cKFAbf/6KOPVFxcrGuvvVaSVF5erquvvlq33HLL8BuTlSXXlClyTZkSeF13t2zbtvmFGm+wqauTfdcuadcuOf75z4C7GpmZ3nU0Rt9pZ0VFMdtv5fkN+7SlrUcvbNgXfmgJJdQUs5QUpTY1yTZ2rP8UM8JMWJiuA8BMTFHFQHiPIJZsLS0thhm/uKurS+PGjdNTTz2ls88+23v5jTfeqKqqKr3++usB91mzZo3OPPNMPfPMMzr99NO1c+dOXXXVVcrOztbTTz8d8ndt+b//i8Iz6OVyKWXXLqU1NCi9vl5pDQ1K277d/XdDg1LaQtfdNxwOdeXnq6uwUF1FRd6/OwsL1VVYKCMjQuFC0oe7HFrR6NCZBU7NGuOM2OMOWm8VMyM1Va7UVBlpae6fTdwkM5Gt2uHQC9tSdGFxj76dZ8LrDSS4ZPiMzV+Xri3tNpVlGlp6aKfZzYEF8R5BpFVUVIS8zrQjxubmZjmdTuXn5/tdnp+fr8bGxqD3mTlzpp566ildffXVam9vV09Pj7797W9ryZIl/f6u8vLySDV70JyS2iVp9+7A9TO1te4Rmt6gk15fL332WcBjuHJzg4/QlJbKyMkJa+SivFy6IELPbTBqamoG1+92e2AVsxhNMUukM0S+z2VKd63+tGuU6rp79OquTF19TP7AD4CIqK6u7vcLF9EVy/6/vrop4T9jP01t905RrRjgO5L3vnnM7Ptw3iOJiPd9bMXVae4vv/xSt9xyi2666SbNmTNHDQ0N+sUvfqGf/OQnWrp0qdnNCy47W67KSrkqKwOv6+yUfds2/8IAW7e6w822bbI3N8ve3Bw00BgjR/qVb/YNNkZhYfwskne5ZOvokDo6/Bf+p6RIGRnuhf+eimYRruAWrwvdg4Ut3+fymwrWw/hKpHAK60iGzxhTVDEQ3iOIJdNCS25urhwOh5qamvwub2pqUkFBQdD7LFq0SEcccYR+/OMfS5IOPvhgjRgxQmeccYbuuOMOlZSURL3dEZWeLtfEidLEiQqYXOB0ytbYGDhC4/l57145vv5ajq+/DnhYIyVFRnFxYOnm0lK5ioulCE47iwrD8FYx81v47wkznkpmnjCTljakPXb6HnTEy8FtsLDl91y6W/iPxEe8hlNYG58xAIgt00JLWlqapk+frlWrVvmtaVm1apXOOuusoPdpb2+Xo88Igudnl8sVtbaawuGQMW6cnOPGyTljhv91hiFba2vw0s21tbLv2CHbli2yb9kS9KFdBQX+pZs9f8aPl7KzY/DkhsgnzPiVZJb2hxnfaWapqf1OM+t70BEvB7fBzvD6PpfqarNaZk1WOyMeL+EYQGh8joHYM3V62LXXXqv58+fryCOP1KxZs7Rs2TLV19friiuukCTNnz9fkrxTv04//XRdf/31euqpp3TSSSepvr5et912mw477LCgJZKHa1hlgqPJZpORkyMjJ0eugw8OvL6jI/QIzfbtsjc2yt7YKH3yScBdjVGj/EdnfKegFRQMaUQjFmw9PVJPj7Rvn/80s9RUd5AZxP4yVju4DSXZz/CGe7Bgtf6Kl3A8GBy4IVkl0ucYiBemhpZzzjlHO3fu1P3336+GhgZNnTpVL774osrKyiRJtbW1fre/5JJL1NbWpieeeEK33367srOzdfzxx+vOO++MSvuiUiY4FjIy5Jo8Wa7JkwOv6+mRrb5+f5Cpq/MLNrY9e+RYv16O9esD7mqkpclVXBxQGMBVWiqjuNgdCqzEMGTr6pK6uvymmRkpKd4F/55Qo9TUiBzcchAXfWYeLETi9Y2XcDwYiXLgFovPLd8NiSWRPsdAvDCt5HEs2TdsGNL9VtZ16IUN+3Sh1UZahqHf0SPDkG3nzoDRGW+w2bkz5OMaNpuMwkJviNk5cqRGH3KI92dlWfyL3bNepndExhtmwgxic19v0sbdPZqcnaIVc82pKJTo1UyW1+yvVhPrg7+BXl+z+z7WB8ZmvhbBDLX/Y/G5tcJ3QzSZ/d5PZtHue6sFbiu1h/d9bMVV9bChMlJTZXO5JGd4tfTnlGQkTFjx6Hf0yGaTkZsrIzdX/5d3kJ7P2qeLvuMTbvbudZdq9kw727p1/8/19bL3/tHHH6uoz+91jR69f4Rm/Hi/imdGbq75G0/6rpeR9k8x85RkzsjwL8kcQiKefbPSfxCSudO9rP76ekY+/uOT1pi8ZlabejdUsXhdrf7eAUKx2oiq1dqD2EmO0DJhgrzDSU6n+09Pj9QbZGwul/ffvn+GEnSs7qLJI7yjR/0JGm5GjpTrwAPlOvDAwDt0d7vXy/SOzrRVVWm0Z4+aujrZW1ul1lY5vvgi4K5GRoa3fHPAnjTjxklmbkAZqiSz76J/z6hMSkrCHMT54j+I/az++noOjJs7XLxmYYjF62r19w6Cs9pJGzNYLXBbrT2InaQILX4cDvcfn2k/oebHGZJkGP5Bx+mUzefffpfFQQUzz+jRyroOXfXWzpBFBgYbbrxSU2WUlclZVianpO01NUr3bC7pcsnW3OxfGKB3Pxp7XZ1sra1ybNwox8aNAQ9rOBwyior896TpHalxlZRIIwLbF/UCCoYhW2en1NnpV8FMdrtfGWbDd38Zs0eShoH/IOKH58DYd9pWXxyEAYPHSRvrBW6rtQexk3yhJVw2m/tMv2e9g4KHHG/A8YSZ3kDjGa35W81ePbe+VZdNytBJxWnukGNEdzlRfwfvAxUZiOjUOLtdRn6+nPn50uGHB16/Z0/w0s21te69aurqZK+rk9asCbirKzc3oHTzx03Z2pNRoBeM3NhO73O5vGFGUvCSzD5hZvl2l5Z8uc/yB4/8BxF/+nvNOAhLToTVoeGkDWAdhJZIstncZ9V9dm73xJIH1xjamJqmr+ptGtvicP/HUZYeMCVNLpc70ASbquZyhRV0PMHk8S/2BISXsEdSomnUKLmmTpVr6tTA6zo7Zd++PfieNNu2yd7cLDU3y7Funfcud/f+3ZORKVvZeLlKSgKnnRUWxnTaWbCSzH9+a6e690kv78zUWaOK3VPNPH/iYGSGg6D4xEFYYhro80hYHRpO2gDWQWiJkZBzze12v5Aj7Q86fv8JTez90vSdqtbTsz/geA6KPZcZhjeYtHS6AkZVwh1JMW3PmvR0ucrLpfJyBawucrncIzGeINNbFMDzJ2XPHunrr+X4+uuAhzUcDhnFxfuDTJ9go4zoP0dvcBxvk23XrsD9ZTzrZnzKMlsJB0HmG0pw5CAsMQ30eSSsWg8nfoDwEFqipO+X0WDmmvcV9D+hPmtyQk5Vczp14vgenXhUj/7yTZue+aJF507OkDEi1T/sDJJV9qzpG56MoiI5i4rkPOqowBu3tvqXbvYNNo2Nsm3dKvvWrUF/jysvL2hhAFdpqTR6dMBIyFBCXcjg6LO/jNra/CuZDbBmZnlNux5cl66fprZH/T9BDoLMR3CEx0CfR8Kq+foeF/D5BcJDaImSUF9G4fzHMayDQk+4SU/X6YeM1OmHFEraH3IC1uB4RmlcrsAiAy6XZaaThRWeRo+Wa/RouaZN87t4ZV2HXl6/S1eM3KWju5r89qOx19bKtm2b7Dt2yL5jh7R2bcDDGllZ/lPNSkv1WXO2OjMK9AdXUfRC3SDWzDy/erd27XFp2Vqb5pWVuEfyooSDoP7F4iwqwREefB6tr+9xAZ9fIDyEligZ6pdRsBGaqOlnDY4vQ9KJ5S6deKx7dMblE2Z8w43fmpxhCjVyEYnw9PyGfdrS6dATqUWacUJl4LQzp1O2hoaghQHstbWytbXJ8eWXcnz5pfcud3jumpIqlRQHrqEpLZWruLjfPV6Gw7Nm5upxPXq6eacuH+OS/ZtOd5jpnV7mO0ojhyMq7ZCSd8pD31GuWJxF5UAViB99jwv4/ALhIbSEIZyDsaF+GVl2uNhuD1h/01+p6M7ubrnKygJGbALKR4fYCyfUiEokqpoNGHx617s4i4vlnDmzz5MzZNu1S598+o3WffaNTjZ2aFJrvXfqmaO5Wdq82f2nD8Nmk1FQ4L8njad8c2mpNGrUsJ6X5O6fA7q7VN7bR94CAO3t/uWZHQ5viPErABCB4gSWfQ9H2ZKqNm1pt3EWFUBQhBRgeAgtYQh1MBbJM8sJc6DTZy8cqZ8CA569cHympZ1z1Ag9U7Vb503OkJGR4ldgQBpeYYBhBR+bTcbYsXosRdpyUJney0rRf50wdv/1+/btn2bWd4Smvl72hgbZGxqkTz4JeOiuUdnakjNOGeWlyq+Y4LcnjZGXF9mKYp69hXw3zZRCr5vp81r2J2Hew2FaUJmlB//RzllUWEqyjnwCSDyEljCEOhiL5JnlZDjQCegv371wep122GiddlixpD7rcHpDzUP/bNAWe7paG6RvT812B57u7pht8hlytGbECLkqKuSqqAi8U0+PbNu36+HX1yttW62mtjXoVO3wrqdJ27Nbk/fslrZ+Jb3jf1cjPd1/hMZ36tm4cZGrLBZq3YynoplndMYz7SwtTctru4MWnUg288ozNaW7UxVJ+NxhXck68gkg8SR1aBnsGSjf262Ymx9w/YLKLP3HJ61q7nBpeU30qzbF+5mzYOFv0M+pt8DADw/P1+NVbbqkMktGwf7bG5I7tHR3By8u4Nn3JszqaX0NabQmJUXG+PGa9p18vbBhnyomj1CH5zEMQ+99XqfVH3+js1KaNW1vnzU1LS1yfPONHN98E/Cwht0uo6jIW7o5b+RIpRxyyP5pZyNHDvl57v8lPhXN9u71G51Z/tYudXbY9NKuDJ01apxfoInlXjiIDt/PpqS4/u5JRsk68hmueP9/Nd7bPxTJ+JwHY6B+ied+s7W0tER3W3YLm/t6kzbu7tHk7JSgYSSc2w32sSIhlr9rqKqrq1URbLQhhFg8p6Af1L7V04LteROBwgLD1tYWvHRzba1sDQ3uYBaCa8wY/9EZnz1pjNzcYU87W1nX4R11CghyviM0qan7A43nTxxsohmOcN/38cD3s2lIlv7uScT+jxfx3vfx8P9qKNXV1bq+Oidu2z9UVnjNrPi+H6hfrNBvQ5XUp0FDnYHqe3A7mDNVsTyblYhnzob7nAZz5iDoNAnPtLTeql59E7y3NHSoMBOrcJOVJdeUKXJNmRJ4XXe3u0xzb4hpq6pSzu7d7mBTVyf7rl3Srl1y/POfAXc1MjP9K5z1TkFzlZbKKCoa1EhJv6NOviM08i/TLPWWavYEGYfD/bPd7r7MU7ab0RpT9f1sJtp3DyDF//+r8d7+oUjG5zwYA/VLPPdbUo+0hBLPKVSK/dBfsN831LMPQ217f6+Z5zFn5KXq4x3d+lG0+iVUuOn7c5TX3NTU1Ki8vNz9g8sl244dsm/d6l8YwFMsYPfu0E/H4ZAxblxg6ebecKNM/z4cTnGEgXjDTW/A8Qs7FhqxseJZt2TSt//jeRpEvOG9bx763jz0fWxxCjOIeE6hUuwXXkby9w31sfp7zTyPaZOiG0KDFBQIOXLTWzjAL9j4/hypURu7XUZBgZwFBdKRR3ov9gSMHxT16ATnjsA9aerqZG9o8P4cjCs31y/IbNmTo1EjCrWirVRziidGNEh4Szd7fu5zvV+ISUlxT0nzDTV9cDCbHFiEDjPxPQNEVtKElkjusdLfY8XySyrU74p16Irk7xvqY/X3mlkuhPbZ1DNosPEUD/AEGZ9/e38eBs8+OM/Wp2j2CZVyVVYG3qizU/Zt2wJLN3tCTXOz7M3N0mefSZKu830Ovx7pP9XMZ08ao6Ag4ptbekNNR4f75z7X+047+9v2Ht3+UZuMFIee7tineeOK9k9HQ0Kx3GcfSYXQDERW0oSWwXx5DDZw9PdYsfySCvW7Yl1yNpK/Lxptj8sSvHa73/4oAcHGMNwhpm+o6e4e1MH3gBtsSlJ6ulwTJ0oTJypg3MfplK2xMXCExvPz3r1yfP21HF9/HfCwRkqKjOJiv2lnvmtqPOuLIskb8rq69PLancrd2y1DNl1XkS371u7eG9lkeNbQ9P4xPGHGd3qaRaaixVo8njWOy88+EgahGYispAgtc19v0oy8VNmkfr88Bhs4+vsiGuqX1FAOCPhCTGI2W8hQ09nRIdcBB7gXv3d37w80XV3egDOsDTYl96L5cePkHDdOzhkz/K8zDNlaW4OP0NTWyr5jh2xbtsi+ZUvQh3YVFLhDTEmJd3TGW745O3vobe7lG9j8+sAwBpyGJsk95c4nyPy1rktPbejU5dNG60BXh7ufPUUEEghnjREJ8Rh+h4rQDERWUoSWwa5nGGwI6O+LaKhfUkM5IOALESHZ7VJGhpSREXyUpjfQqKfHXd2rd5RmuNPOJLlHLHJyZOTkyHXwwYHXt7fvLwTQN9hs3y57Y6PsjY3SJ58E3NXIzvYWAuhbHMDIz3c/7wEMO7C5XO4S093uEZo/frpTu9t69OqenfrZhN2yewoUWHzkJtyDR06SIBIIvwCGKilCy+TslEH9RxuNEDDYA4NIHBAM5wyWGWe/kumMm6XYbO4pWEHKPHunnXV1yeYZnenudv87UsUBMjPlmjxZrsmTA6/r6ZGtvt6vyplvsLHt3i1HVZUcVVUBdzXS0+UqLvarcOYNNsXF3lGpSPObatftU41tsCM3Dod/uElNdf/suczz7wiHm3APHjlJgkgg/AIYqqQILWaWLR7owMD3wH247RzOGaxonP0aKJRY/YxbvIXAwRiwXT7TzvzCjOQOLb6BxvffRvDK6WGXQU5JkVFaKmdpaeA6GsOQbefOgNEZb7DZuVOOTZukTZsCHtaw2WQUFgaWbvZMO8sa+gGU78hNTc0QHsDpdFeM693LRpJWBes3h0OGZw8bz8hN31GbMPa04eARZiD8AhiqpAgtwUTioHIwjzHQgUEkD9yHcxASjQOYgZ6b1Q+arBYCI2FY7fKc8e8z5cyQ9hcB6DNC46lS9sKGfcPfu8Vmk5GbKyM3V67DDgu8fu9e77Qz7740nmlo9fWy9/7Rxx8H3NWVkxMQZDyFAYy8vJhP4Qrab55w0zstTQoychPGlDQOHgEA8SRpQ0skDioH8xgDHRhE8sB9OAchoe4bTrjzve0UDfzcBtNeM0csrBYCIyFq7fKUcB4xwi/QfGdOgZ5at1PfnZwuIzfFHWY8wSbMTTYHHLUZOVKuAw+U68ADA6/r7navl/Edodm6Vba6OnewaWmRWlrk+PzzgLsaGRneqWYBwWbcuLBGNwZrUNXdgglnSppn1KY30PiWhfabmmYyq45aAgBiy9bS0hJ8XkeCW17T7j14G85Iy3AfIxKi+Z96fzvN93fb31S0RGSX2HB+vxmseEDlu0OvFdvn5ZkS5Ts609UVshjAVW/t1Ja2Hk3IStF/nTA2cu1wuWTbsSNg/Yy3UEBra8i7Gg6HjKIib6hpHjlSOYccsn/a2YgwQ4fVeEZufNfYeKal9R29GaZQ79VwvgPYndo89L156Hvz0PexlbQjLb5n+Yd6YGeV6RXRnIoUzpl5v9t2t8T895vBzGlgg3nfWnWamiT3QW9mppSZGVgMIEiYuWjySL2wYW/4ow8DsdtlFBTIWVAgHX544PV79gQv3Vxb696rpne0RmvWaFyfu7rGjvVOM3P5brBZWipjzBjr7/kSZORGCj564zdS0ztK4zdVzRN0QlR4C/Vetfp3QLyx9IkMAOhH0o20BPvCjvez+ZEc8YnUf2jJcvbBzNG2UO/bviMtVhgNjBjfMNPZOWAhgKjr7JR9+3bZtm6VvbZWbVVVytm92x1stm1zty0EY8QIb5WzgGlnhYVRmXYWa0Gn9HlGb+x2vyDj3e+mMltnTBw5pClqyfK9MxzR+v+OvjcPfW8e+j5yPMefr/fzvRTW/4oPPvig/vKXv+ivf/1r0OvPOOMMzZ07V9ddd114LY2hYGfzrH4mb6Cz5ZEc8bH0mXkLMnO0bTDvW6uMBg5VQIgOVdnMtzyzb5gJc91M2NLT5Sovl8rL5ZS0vaZG6eXl7uucTtmamoKO0Nhra2Vra5Pj66/l+PrrgIc1HA4ZxcXukZm+e9KUlLj34IkDQQsKeEZv+jh9lHT64ZLUKm3rMyXPM2rjO0XNd2qa53IMyOr/3wFITp7jz/6E9S3/0ksvac6cOSGvnzFjhl544QVLh5ZgX9hWPLDzPViL5X8y/IcWP6z4vo20/kJ0QKBJTZW0f98ZQ3JPa/KMznR1SZ2dsQkzkvtAu6hIzqIiOY86yv86w5BaW4OXbq6tlb2pyT16s3Vr0Id25ef7hRi/8s2jR1tm2tmQCwr05amc5iPYM0yvrZUtLS1gj5u+paKjse9NvEiG7w0A8cdz/NmfsEJLTU1Nv8NgkyZN0rJly8J5yJiLly9s34O1FXPzY9bmeOkfJIf+QvSgRgU9B6k+Vc28YaazM/YjMx42m5STI1dOjlwHHxx4fUdHYGEAT/nmbdtkb2qSvalJ+vTTgLsao0YFjs54/l1QEHJNSTT47mETE07n/j2EfAxYQc2zBseiFdQAINEN5vgzrNCSnp6u+vr6kNdv375d9hj+hxjPBlo7wohHYmDR6/D09yUW7mck4LXonU4UcmTGs+9MV5e70lksZWTINWmSNGlS4CabTqdsDQ3+pZt9Q82ePXJ8+aUcX34Z8LBGaqpcxcWBa2jGj5eruNg9/S4JhCqfHTTc9F2D4zuC41tZbYBCAwCA4QkrtMycOVPPPfecfvSjH2n06NF+17W0tOi5557TrFmzItrARBXLdSowT9/XmRATOeF+RoY1MuN07l/47zPNbOXWff3vHRMNvetdnMXFcs6c6X+dYci2a1fA+hl7ba17T5rmZjk2b5Y2bw54WMNmk1FQEHSExlVaKo0aFZOnN+B+PBEQ1qanIdbgSIMIOZ6RG99pasGCTpJOVQOAcIQVWm699VadccYZOu6447RgwQJNnTpVklRVVaXHH39cTU1Nevrpp6PRzoRjlZGUcA+ik/2gO9zn3/d1ptCBeYb1mXM43Huu9AkzD3yxXVtTR2hXk/TtadlyjRghIzXVfZBrRkUzm03G2LEyxo6V69BDA6/ft2//iExvmGnZuEXG1lrl72qUvaFB9oYG6R//CLirMXp0wPoZT7Ax8vIiNsIQVqAYooittQnGN+R0dfldFTKa2O0hA43Rp8oaQQdAsgq75PFbb72l66+/Xps3b5at90vTMAyVl5frwQcf1IknnhiNdiJKwi1/OZjbL69p14P/aNJPj/RfixPrwBOJ39f3MYZbLjQWJYgpwRg7fV9Pv77vLcvsGZlRZ2fIM/Zm8mzaeUCm9PiBXaH3pOnoCPkYRnq6u3Rzn1DjKi2VUVzsLZIwGCvrOryBItzQUlNTo3JP9bZEN9ig4xt2ohh0+N4xD31vHvo+tsKuEXnCCSfo008/1WeffaZNmzZJkiZOnKjDDjvMG2IQP8I9+zyY2y+patOWdlvAaEKsRxki8fv6PsZwR8iY9pdY+n09U1Ol1FT/8swu1/4A45lm1tVl3j4z2j/qcP7kETJKMuQsLQ1cR2MYsjU3By/dXFsre0uLHN98I33zTcDjG3a7jMLC0NPORo70u33MF+/HK5dLNpcrYONPKQIjOr5hh//XAVjEkArb22w2TZ8+XdOnT49wcxBr4R5ED+b2Cyqz9OA/2gMO7GM9JS4Sv6/vY8QidCT7FLyEZrdLmZlSZqb/mhnfAONZOxOjUZlBhQSbTUZenpx5eVKw7/22ttAjNA0Nsm/fLvv27dJHHwXc1TVmjH+Q8dls08jN5aA5kqIYdGzd3e61X1RbAxAlYYWW9957b1C3O+6444bUGPQvXg5m55Vnakp3pyr6tDHWowyR+H1mjIyw7iUJ+Wya6f2cTxmhecWO/XvLeKqaWXCKmbKy5JoyRa4pUwKv6+pyl2nuW7rZ8+9du6Rdu+T45z8D7mpkZgZsrOn9uaiIDSVjYZBBJ23bNtk91edCTFEzUlLcITRYMQIAGEBY3/jf+c53BjUFbOfOnUNuEELjYDY5WKVIA8zh/Zx/uU/zDsiXMjICp5h5RmZ8p5qZOMWsX2lpMsrL5SwvD5x25nLJ1tQUOO3ME2x275ajulqO6uqAhzUcDhnjxvlNNctOS5O9p0eukhL3iFYMxKLaWbxZuWXv4EtKe4SYouZXbrrvvxFSvJzkRPQk4nsgrNCyfPnygMucTqe2bNmi3/72t3K5XFq4cGHEGgd/HMwmB9a9JLcBP+d2u5SR4RdmDMNwB5mODv+1MrHaLHOoete7OAsLpSOPDLx+927/0s1bt7pLN9fWyt7Y6A06HhN87urKzfVfQzN+vPdnY/ToiE07i0W1s3gzpD5xOmVzOge3MaiHb9DpE3hClpdOEpzkRCK+B8IKLd/61rdCXnfJJZfojDPO0LvvvqsTTjhh2A1DIA5mzZOIZywSTaK8RkP6nNtsUnq6lJ5umbUyEZGdLVdlpVyVlYHXdXTIvm2b3whNZ3W1RjY3u6ejNTfL3twsffZZwF2NkSODlm52lZbKKCgI6+A2quWT41TM+iRE0JH6CTvBAk1KivuyUMUI4hAnOZGI74GwSx73Z+nSpXrwwQf1ZZCdmJFcfMsAWv1gcjDtG26p41gKpwSj1V+bcFjhNYqL8pc9PYGlmIMc9MUjb8ljp1O2xsaghQHstbWy7d0b8jGM1NSAaWfeYFNc7B7lQoCELTftu1noYCqumbCHTlx87yQo+j62IrqKcdeuXWptbY3kQyIBWH2IcjDtS8QzFpL1X5twJOprFHEpKe4zyz6lhq1YinkoPtzl0H9s3tm7lmKcnOPGyTljhv+NDEO21tbgpZtra2XfsUO2LVtk37Il6O9wFRS4Q0yQPWk0enQMniViynez0D5CRpM4CDpAPAortGzdujXo5a2trXr//ff1yCOP6JhjjolIw5A4rH4wOZj2JerUPKu/NuFI1NcoJixYinkoVjQ61NAzwFoKm01GTo6MnBy5Dj448Pr2dv8KZ77BZvt22RsbZW9slD75JOCuxqhR/qMzJSX719Lk58ftVCOEaShBxxNoUlK8U9a8hQh8fqZiHpJZWO/+Qw89NGT1MMMwNGPGDD344IMRaRgSh9UPJq3evmhK5ueOQfApxexheKaXdXZKHR2WCjJnFjj15u6M4a2lyMyUa/JkuSZPDryup0e2+vrQe9Ls2SPH+vVyrF8fcFcjLc1vDxq/8s3Fxe6+RvIKpxBBnzCTsmuX1NLiDsV9Qg+QSMIKLY8++mhAaLHZbMrJydHEiRM1JViNfgBA4gg2vcw3yHimmZkQZGaNceqCw8dG7xekpMgoLZWztDSwfLNhyNbc7L8HjW+w2bVLjk2bpE2bAh7WsNlkFBbuH5XpM/VMWfE/EooI8gScXo7du2XfsSPwdr7T1HzCjOE7Lc1zOQEHcSCs0HLJJZdEqx0AhiCRFtIjjgULMk6nf5Dp6LDMiExU2Gwy8vLkzMuTpk8PvL6tLTDIeKah1dfL3vtHH30UcFdXTo5fhTPfimdGbi7rIRCc7zS1ri7vxUHfLZ6A4xtmetffJHv5aFgHkyOBOJZIC+klQlhCcTikESNkjNg/VctvY8zu7v3rZZwB4xaJJytLroMOkuuggwKv6+52r5cJNu2srk72lhappUWOzz8PuKuRkeGdamb0jtR4g01REWsgMDiegBPkxEJY5aPZEBRRFPa3WWNjo5599lmtXbtWu3fvlqvP5mU2m02vvfZaxBoIILR4W0g/UCgZSggj6MSRYBtjSu7Q4lno71uGOc6qlw1ZaqqMsjI5y8oCp525XLLt2BG0MIC9rk621lY5Nm6UY+PGgIc1HA4ZRUXB96QpKZFGsLcMhiHcDUFtNveGsoMJOnG+Tw6iI6zQUlVVpe985zvat2+fJk+erKqqKk2ZMkUtLS3avn27Jk6cqJKSkmi1FUAfkVpIH6sD/76hpO/vHUoIS7TRpqTUOyqjESP6rV5m6+xMjlEZX3a7jIICOQsKpCOOCLx+z57QhQEaG90jNXV10ocfBtzVlZsbtHSzUVoqY8wYpp0hsgxjSEEn1MgNQSf5hBVa7rrrLmVkZGjVqlXKysrS5MmTde+99+qEE07Qyy+/rJtvvlnLli2LVlsBREmsDvz7hpK+v3coISzeRpsQhj7Vywxp/+aYJi/6t4xRo+SaOlWuqVMDr+vslH379uB70tTVyd7cLDU3y7FuXcBdjREjvCMyAetpCguZdobYYJ8c+AjrW2f16tW69tprNWHCBO3atUuSu9SxJJ133nlavXq1fvGLX2j58uWRbymAqInVgX/fUBKJ30vZ5iTTz6L/ntZWGaNGuRf99zmTm5TS0+UqL5fKy4NPO2ts3B9k6upk37p1/89tbXJ8/bUcX38d8LCGw7F/hKakRF+NKtLyrmwdPWufZhx+gHsKYJxYWdeh5zfs692QNH7ajX4QdBJWWKGlu7tbRUVFkqSM3i+l1tZW7/WHHHKIXnjhhQg2D0AsmHXgT+AYGtbx9OFwaHmjTQ/W5OunudmaV17oPqHmGYnxnWbWZx1m0rLbZRQVyVlUJOdRR/lfZxhSa2vg+hnPv5uaZNuyRfYtWyRJh/T+0XPuu7vy8/evn+lbvnn0aEsd7D2/YZ+2tA2wISkS31CCjt2utLo62TIyAsKOYbcHBiDPzxiysELL+PHjVVtbK0nKzMxUUVGR1qxZo+9+97uS3GteRvqc/QIwfBygoi/W8QRaUtWmLe22/X1iswVf9O9btcy3khn2s9mknBy5cnLkOvjgwOs7OvxCzLavNqulukYHtjVqZON22ZuaZG9qkj79NOCuRlaWdz+avnvSGAUFMV+PcNHkEXphw77hbUiK5ORyydbT456q2ke/sbyfUGOEqrrGOh1JYYaW2bNna8WKFfrZz34mSTr//PP12GOPeauI/eEPf9Cll14alYYCyYoDVPTFOp5ACyqz9OA/2gfuk9RUd7Uun4v8RmWSrRTzUGRkyDVpkjRpkpyS8iXtramRUV6utp4e2Roagq+h8Uw7W79ejvXrAx7WSEuTq7g4+J40xcXuNU4RNqckgxEWxFafzUF9DaryWrApbDZbUoSdsELL9ddfr9mzZ6uzs1Pp6en6+c9/rpaWFr366qtyOBy64IILdPfdd0errUBSSoYD1HgbTTK7vUyrCzSvPFNTujtVMZR+CTUq41n033dUJllKMQ9FSoqMkhI5S0rknDXL/zrDkG3XrsDSzZ41Nc3NctTUSDU1AQ9r2GwyCgr2B5k+e9IoK3G/HwG/ymtBDLrM9EDT2HxvZ0G2lpYWvn0xJP0duFVXV6uiosKklsWXSB8Ax2Pfz329SRt392hydopWzM03uzkDCtXeeOz7RBKT/jeMwFLMjMqopqZG5eXlw3uQvXv3j8j0XU9TXx/ygE2SXKNHBx+hKS2VkZdnqXU0kRaRvseQJGzfewoThBjBCblmJ8phh5qFGDKmLUVGMvZjuPuzmD2y0Ve8jH5Zrd+GwzLPxWaT0tOl9PTAtTIdHe4A09HhnufOov/wjBwp14EHynXggYHX9fTItn17yD1p7K2tUmurHF98EXBXIz3dWxAgINiMG+eeMghgP9/CBEHW/A2qCluwvXVCrdkZ5EkFQguGLFIHbpY5GDGJVQ6AY/k6hLs/i9nBrm/fxMv0LLP7LZIs/1z6rJXxCzKdnfsDDUFmaFJSZIwfL+f48YHlmw1DtubmwCDj+bmlRY5vvpHjm28CHtboraIWak8aUVwIGLx+qrBJgws7RllZyPsTWjBkkTpws/zBSJRZ5QA4lq9DuEHN7GAXr+9Rs/stkuLyuXiCzKhRknqDjO9IDGWYQwpr/xSbTUZenpx5edL06YHXt7UFrp/p3ZPG1tAg+7Ztsm/bFvShXWPGBAQZz4iNMXZsQk87A2LGJ+z0t2aF0ALTxeXBSAKK5esQblAzO9jF63vU7H6LpHh7LiFHLtPSpLQ0/xGZvmtkOjvjco1MJDdqjOj+KVlZck2ZIteUKYHXdXXJtm2b3/oZv4pnu3ZJu3bJ8c9/BtzVyMz0Xz/jW765qMi9ESqAiOETBdPF28FIouJ1CI2+QbjCGp0LFmQ8lct6R2TU2dnvtAsriGTQiNn+KWlpMsrL5SwvD5x25nLJ1tTkDjNbt7pHaHxHbPbskaO6Wo7q6oCHNRwOGePGBS0M4CotdVerAxAWQgsAABE27NG5lBT3Og6fNRWG0+m32N9qQSaSQcMS+6fY7TIKC+UsLJTzyCMDr29tDV66ubZW9sZG7/qaYFx5ecELA5SWyhg9mmlnQBCEFgAAImw4o3Mhp5Y5HNLIkcGDjAVGZCwRNGJp9Gi5Ro+Wa9q0wOs6OmTfti34njTbtsm+Y4fsO3ZIa9cG3NUYOTL4CM348TLy893vAyAJEVoAALCQsKaWBQsyvlPLPIEmDtfIxLWMDLkOOEA64IDAaWdOp7sAQLDSzXV1su3dK8dXX8nx1VcBD2ukpspVXOw3QjMqNVV2w5CruNhdjhtIUIQWAAAsJNJTyyi/bDEOh4ziYjmLi+WcOdP/OsOQraUleOnm2lrZm5vl2LxZ2rzZe5dyz11tNhkFBSH3pFF2dsyeIhANhBYAACwkKoUfgpVf9t0Q0yJVyyJZgSwu2WwyxoyRMWaMXIccEnh9e7t/hbPaWnVWV2tkc7N7882GBtkbGqRPPgm4q5Gd7d2Ppu/UMyM/P+q7mQ9W0r8HEkQ0XkdCCwAgoST7hrWDFmxDTJOrlkW01HEiysyUa/JkuSZP9l5UU1Oj8vJyqadHtvp6/6lmvqM1u3fLUVUlR1VVwMMa6ekB0868waa42P1eiRHeA4khGq8joQUAkFDidTNQSwhVtayz072niadqWXd3VH59zEodJ6KUFBmlpXKWlgauozEM2Zqb/feg8Z16tmuXHJs2SZs2BTys0VtFzRtifEZqXKWlUlZk96/iPZAYovE6EloAAAklXjcDtSyHQxoxQhoxYv+ojMu1fySms1NGWlpEflXSVSCLFZtNRl6enHl50vTpgde3tQUGGc+/Gxpk375d9u3bpY8+CrirKycnaOlmV2mpjNzcsMs38x5IDNF4HQktABJSOFOEPLedkZeqj3Z0e/9melF8YjPQGLDbpcxMKTNThqSu3bvlmjTJHWR89pKxdXdLhjHgw8FkWVlyHXSQXAcdFHhdd7e7THOwPWnq6mRvaZFaWuT4/POAuxoZGSELAxjjxrlH9oBB4t0CICGFM0XIc9vPd3YrM8Xm/ZvpRUAYbDb3Tu8ZGftHZAzDb0SGIBOHUlNlTJgg54QJgdPOXC7ZduwILN3sWVPT2irHxo1ybNwY8LCGwyGjqChwhGb8eLlKStyhGPBBaAGQkMKZIuS57VF5qfp4R7f3b6YXAcM0mCDT2ekemSHIxB+7XUZBgZwFBdIRRwRev3t38NLNdXWyNTa6R2rq6qQPPwy4qys3N/gITWmpjJycsKedIf4RWgAkpHCmCDGdCIihUEHGM6XM92+CTHzLzparslKuysrA6zo7Zd+2LfieNNu2yd7cLHtzs/TZZwF3NUaODFq62VVaKqOw0L0OCwmH0AIAgAkozezDZnPv5p6eHhhkfKeWEWQSR3q6XBMnShMnBk47czpla2oKWhjAXlsrW1ubHF9/LcfXXwc8rJGSIqO4OPieNCUl7sCMuERoAQCEJd4Otq3aXkozDyBYkJECp5Z1dhJkEk3vehdnUZGcRx3lf51hSK2tgetnPP9uapJtyxbZt2wJ+tCu/Hy/EOOdejZ+vDR6dAyeHIaK0AIACEu8HWxbtb2UZh6iYEEm2NQyl8vERiJqbDYpJ0eunBy5Dj448PqOjoCNNb0jNNu2yd7UJHtTk/TppwF3NUaN8l8/4ztSU1DgrpoH0xBaAABhibeDbau2l7VUEZSWJqWlJX2QWVnXoec37NNFk0dEda+TWP2eIcnIcJffnjQpcNpZT49735m+a2h696ix7dkjx/r1cqxfH/CwRlqaXMXFfutnRqWmyi7JVVzsfg8iqu8NQgsAICzxdrAdb+1FhAQLMt3dgUHGGXBoOyxmHtA/v2GftrT16IUN+6L6u2P1eyIuJUVGSYmcJSVyzprlf51hyLZrl/8Izdat+0dtdu6Uo6ZGqqnx3qXcc1ebTUZBQdDCAK7SUmnUqBg9QfNF871BaAEAAMkhNdW970jvj4Yk9fTsL7vsWSfT3T3kX2HmAf1Fk0fohQ37dOHkEQnxe2LKZpMxdqyMsWPlOvTQwOv37t0/ItMbajo3bNDI5mbZtm+XvaFB9oYG6R//CLirMXq0X4jxDTZGXl5ClW+O5nuD0AIAACwvagUVUlLcZ+BHjvRe5Fe5rKtL/7ehRS9UteiSSRkDBhEzD+jnlAzcvnj6PZYycqRcBx4o14EHei+qqalReXm51N3tDi6h9qRpbZWjtVWOL74IeFgjPT3kCI0xbpz7/RlHovneiK+eAAAASWmgggoRDTV9Kpc9sMbQxhEj1dBq6MQjRvU7vSwpD+iTXWqqjLIyOcvKAtfRGIZsO3YEL91cWyt7a6scGzfKsXFjwMMavVXUQu1JoxEJNNI1CKaHlieffFIPP/ywGhoaNGXKFN1777069thjg952wYIFev755wMuHzFihLZt2xbtpgJJxaplYgEkp4EKKkSzSpznd19VmSWNygycXua7TqazM+LrZBDHbDYZ+fly5udLhx8eeH1bW/ARmtpad9GAujrZ6+qkNWsC7uoaOzawdHNvsDHGjk2oaWeSyaHllVde0a233qoHHnhARx99tJ588kmdf/75Wr16tcaPHx9w+/vuu0933nmn32WnnXZayJADYOisWiYWQHIaqKBCNKvE9fu7U1KkrKzg62R6N8VUV5dsPT0RbxcSQFaWXFOmyDVlSuB1XV3uMs0+U838Kp7t3Cnt3CnHunUBdzVGjPCGmb7BxigqirtpZ5LJoWXx4sW6+OKLddlll0mS7r//fr355ptatmyZFi5cGHD70aNHa7TPxj+rV69WTU2Nli5dGrM2A8nCqmViASAYS1WJC7ZOxjfIeBb8E2TQn7Q0GeXlcpaXB047c7lka2ryVjmz9QYa7yjNnj1yVFfLUV0d8LCGwyFj3Di5xo93B5mSEv9pZxnWnN5oWmjp6urS2rVrdd111/ldPmfOHH344YeDeozf/va3mjp1qmb1LVsHYNgsdQAARABTHmGqYEHG6fSbWkaQwaDZ7TIKC+UsLJTzyCMDr29tDdxc0xNsGhu909CCceXlBS8MUFoqY/Ro06admRZampub5XQ6lZ+f73d5fn6+GhsbB7x/a2ur/vSnP+mOO+4Y8LbVQVImoo9+Nw99bx763lz99f+D69K1pd2mB//RrindnTFsVXLgvR8hTqfs3d2ydXZ6/x4oyNT47B2C2LJ0348cKR10kPuPD1tnp9IaG5XW0KC0+nqlNTQovffv1MZG2XfskH3HDmnt2oCHdI4Yoa7CQnUVFqqzqMj976IidRUVqXvsWMnhGFaTyyZPDnld/E1o6/Xiiy/K5XLpwgsvHPC2FRUVMWgRfFVXV9PvJqHvzUPfm2ug/v9part3ymMFIy0RxXs/ylyu/WtjPCMyvXvJeMvuIubiuu/7BBlJ6pLU5XTK1tjoXxhg61bvmhrH3r3K3LRJmZs2BdzfSE11TzvrO0IzfrxcxcXuinwDcPVznWmhJTc3Vw6HQ01NTX6XNzU1qaCgYMD7//a3v9VZZ52lMWPGRKuJAIAEwpRH62CqXpjsdnd52xEj9i/4d7mkzk71tLbKGDXKPc1sGJtiApKk3vUuznHj5Jwxw/86w5CtpSV46ebaWtmbm2XbskX2LVsCHtaw2WQUFPgXB/BdR5OdPWDTTAstaWlpmj59ulatWqWzzz7be/mqVat01lln9Xvff/zjH/r888917733RrmVAAAg0qhOGAF2u5SZKWd2tozCQkm9m2L2VizzlmDu7pYMY4AHAwbBZpMxZoyMMWPkOuSQwOv37fOvcOYbbOrrZW9okL2hQfrkk4C7GtnZcpWWqu3990P+elOnh1177bWaP3++jjzySM2aNUvLli1TfX29rrjiCknS/PnzJSmgOtjTTz+tSZMmafbs2TFvMwAAGB6qE0aJzeau/JSRsX9ExjAk380wPX8TZBBpI0bIVVEhV7Cpoj097uASak+a3bvlqKrq9+FNDS3nnHOOdu7cqfvvv18NDQ2aOnWqXnzxRZWVlUmSaoNUNdizZ49eeeUV3XzzzbFuLgAAiACm6sWQzeZeS5Ce7r+XTLAg4+pvRQEwDCkpMkpL5SwtDSzfbBiyNTeHrGbmfYioNW6QrrzySl155ZVBr1uxYkXAZaNGjVJdXV20mwUAAJC40tLc+4D0/mhIUnd3YJBxBhxiApFls8nIy5MzL6/fm5keWgAAAGABqalSaqp/kOnp2R9g2BQTJrKb3QAA8WF5Tbvmvt6khWtaNPf1Ji2vaTe7SUBC83zmkv2zFqof6J8YSUmRsrJkjB0rY9w4GeXlck2cKFdxsYzcXBlZWTJSOAeO6CO0ABgUT7Wf//56n7fqD4Do8a2wlcxC9QP9YyKHw11+ecwYGUVF7iBzwAHucrZ5eTJGjZKRmmp2K5FgCC0ABmVBZZYmZ6foigNHaHJ2ClV/gCjzfOaS/bMWqh+G0z+M0kRBbwlm5eTIKCyUMWGCXJMmuffhyMuTkZ0tIz3dXRjAIlbWdeiqt3ZqZV1HRG+bqMzuA8bzAAwK1X6A2OIz5xaqH4bTP+wTEyODKcHc2Wla5bLnN+zTlrYevbBhn+aUZETstonK7D5gpAUAACQVRrFM5CnBPHq0jPx8987oBxwgV1mZXAUFMnJyZGRmukduouyiySM0IStFF04eEdHbJiqz+4CRFgAJZXlNu5ZUtWlBZRZnUAEExSiWBYUqwdzZKZunallnZ0RLMM8pyRj0iEE4t01UZvcBIy0AEgqLc2ElrJ0AhiE11V25LDdXRnGxu2pZeblc48a5q5mNHEnlsiTCKw0goSyozNLjVW1M+4AlsHYCiLCUFPfu6iNHei8ynE6/ERl1dsrW3W1iIxENhBYACYVpH7ASQjQQA54SzCP2r7UwXK79Acbzd1eXiY3EcBFaACQt1r8g2gjRSAaW/C71lGDOzPSvXNbZ6a5cNsggs7KuQ89v2KeLJo9I+jUtZmNNC4CkxfoXABi+uPku9ZRg9uwlU1bmv5dMkE0xfcv8wlyEFgBJi7KnADB8cf1d2jfITJjgLsFcUiJXXp7OP7RAJaMzkrrUsVUwPQxA0mLqDgAMX8J9l/pMLTt5Ro5OnlEuOZ1yedbHdHS4p5khpggtAAAAQH+CLPbvbG+Xa9w4b5CJ9D4y8EdoAQAAAMKVkiKNHOktv+zdELOjw73A3xNkXC5Tm5koCC0AAABAJKSmSqmp+yuWSZInwPgGGcPo50EQDKEFAAAAiJa0NCktzT/I+O4h4wk0BJl+EVoAAACAWEpPl9LT/feQ6eoiyPSD0AIAAACYyWYLDDKS/4iMZzPMJF0jQ2gBAACDZsndz4FEFSzI9F0jkyRBhtACAAAGzXf3c0ILYIJga2R8p5Z5/k6wIENoAQAAg7agMkuPV7XF5+7nQKLyBJlRoyQlZpCxm90AAAAQP+aVZ2rF3HxGWUy0vKZdc19v0vKadkv/vli1M9b9ESmedi9c0zLo9ve9T7/3TUuTRo2SkZen17rH6vQvR+k1o0CuwkIZY8bIyMyUHA6trOvQVW/t1Mq6jig8y8ghtAAAAMQR3yl6Vv59sWpnrPsjUjzt/u+v9w26/X3vM9j7eu63pLrTHWRyc2WUlMg1caIeaB2rNY6x+q/tqTJGjJAcjkg9xYgitAAAAMSRBZVZmpydErMpekP9fbFqZ6z7I1I87b7iwBGDbn/f+wz2vv310dWHjlFxwWhddHSZjOJiuSZOlKu8XK6iIhljx8oYMUJGivkrSmwtLS0UgEbEVVdXq6KiwuxmJCX63jz0vbnof/PQ9+ah782TdH3f0+O3RkadnbL19ET0V7gmTw55nfmxCQAAAIC1paRIKSkyRo70XmQ4nX7ll6MRZLy/PiqPCgAAACCxORzSyJExCTKEFgAAkLDYDBOIsVBBxndqWUdH2EGG0AIAABIWm2ECFuBwSCNGuKuT9TJcLvdITFeXbL0jMv0htAAAgITFZpiARdnt0ogR7jAziJsTWgAAQMKaV57JCAuQANinBQAAAIClEVoAAAAAWBqhBQAAAIClEVoAAEDcWF7TrrmvN2l5TbvZTQEQQ4QWAAAQN3xLGANIHoQWAEBS4ox9fFpQmaXJ2SmUMAaSDCWPAQBJiU0H4xMljIHkxEgLACApccYeAOIHIy0AgKTEGfvEtLymXUuq2rSgMovXF0ggjLQAAICEwUJ9IDERWgAAQMJg2h+QmJgeBgAAEgbT/oDExEgLAABAHKBMN5IZoQUAAJiKg/HBYb0OkhmhBQAAmIqD8cFhvQ6SGaEFAACYioNxt4FGnOaVZ2rF3HzW7MQZRhIjg9ACAABMZbWDcbMOMhlxSky8rpFBaAEAAPBh1kEmI06Jidc1Mih5DAAA4GNBZZYer2qL+UEm5ZoTE69rZBBaAAAAfHCQCVgP08MAAAAAWBqhBQAAAIClEVoAAAAAWBqhBQAAAIClEVoAAAAAWBqhBQAAAIClEVoAAAAAWBqhBQAAAIClEVoAAAAAWBqhBQAAAEgiy2vaNff1Ji2vaTe7KYNGaAEAAACSyJKqNm3c3aPHq9rMbsqgEVoAAACAJLKgMkuTs1P0o8oss5syaClmNwAAAABA7Mwrz9S88kyzmxEWRloAAEDcise5+QDCR2gBAABxKx7n5scSoc56eE2GhtACAADiVjzOzY8lQp318JoMDaEFAADErXnlmVoxNz/u5ufHCqHOenhNhoaF+AAAAAkqHhdcJzpek6FhpAUAAACApRFaAAAAAFgaoQUAAACApRFaAAAAAFgaoQUAAACApRFaAAAAAFgaoQUAAACApRFaAACIkOU17Zr7epOW17Sb3RQASCiEFgAAImRJVZs27u7R41VtZjcFABIKoQUAgAhZUJmlydkp+lFlltlNAYCEQmgBAItjylH8mFeeqRVz8zWvPNPspiS9eP7cxHPbgWgxPbQ8+eSTOvTQQ1VYWKgTTjhB77//fr+37+rq0n/8x3/o0EMPVUFBgQ4++GA9/vjjMWotAMQeU46A8MXz5yae2w5Ei6mh5ZVXXtGtt96qG264QW+//bZmzpyp888/X1u3bg15nx/+8Id688039dBDD+mjjz7S008/rWnTpsWw1QAQW0w5AsIXz5+beG47EC0pZv7yxYsX6+KLL9Zll10mSbr//vv15ptvatmyZVq4cGHA7VeuXKm3335bn376qXJzcyVJEyZMiGmbASDW5pVnMt0ICFM8f27iue1AtJg20tLV1aW1a9dqzpw5fpfPmTNHH374YdD7rFixQocffrgWL16syspKHXHEEbr55pvV1sbwKQAASCysbbEeXhPzmDbS0tzcLKfTqfz8fL/L8/Pz1djYGPQ+NTU1Wr16tdLT0/XMM8+otbVVN998s+rr6/XMM8+E/F3V1dURbTsGh343D31vHvreXPS/eej7yHtwXbq2tNv04D/aNaW7M+Tt6PvY8X1Nlh5K30daRUVFyOtMnR4WLpfLJZvNpieeeEKjR4+W5J5Sds4556ixsVEFBQVB79dfByA6qqur6XeT0Pfmoe/NlUz9v7ymXUuq2rSgMssS04iSqe9j6aep7Xq8qk0/qsxSRYjXmb6PLd/XRN219H0MmRZacnNz5XA41NTU5Hd5U1NTyPBRWFiocePGeQOLJB144IGSpNra2pD3AwAgkfhWl7JCaEF0sLbFenxfEwZZYsu0NS1paWmaPn26Vq1a5Xf5qlWrNGvWrKD3Ofroo1VfX++3hmXjxo2SpPHjx0evsQAAWAjVpQAkG1NLHl977bX6/e9/r2eeeUZfffWVbrnlFtXX1+uKK66QJM2fP1/z58/33v68887T2LFjde2112r9+vVavXq1br31Vn33u98NWBsDAECiYhNLAMnG1DUt55xzjnbu3Kn7779fDQ0Nmjp1ql588UWVlZVJck/58pWVlaU//elPuvnmmzVnzhzl5OTozDPPDFoeGQAAAEBiMH0h/pVXXqkrr7wy6HUrVqwIuKyiokL/8z//E+1mAQAAALAIU6eHAQAAAMBACC0AAAAALI3QAgAAAMDSCC0AAAAALI3QAgAAAMDSCC0AAAAALI3QAgAAAMDSCC0AACApLK9p19zXm7S8pt3spgAIE6EFAAAkhSVVbdq4u0ePV7WZ3RRYHAHXeggtAAAgKSyozNLk7BT9qDLL7KbA4gi41pNidgMAAABiYV55puaVZ5rdDMSBBZVZeryqjYBrIYQWAAAAwAcB13qYHgYAAADA0ggtAAAAACyN0AIAAADA0ggtAAAAACyN0AIAAADA0ggtAAAAACyN0AIAAADA0ggtAAAAACyN0AIAAADA0ggtAAAAACyN0AIAAADA0ggtAAAAACyN0AIAAADA0ggtAAAAACyN0AIAAADA0ggtAAAAACyN0AIAAADA0ggtAAAAAIZleU275r7epOU17VF5fEILAAAAgGFZUtWmjbt79HhVW1Qen9ACAAAAYFgWVGZpcnaKflSZFZXHT4nKowIAAABIGvPKMzWvPDNqj89ICwAAAABLI7QAAAAAsDRCCwAAAABLI7QAAAAAsDRCCwAAAABLI7QAAAAAsDRCCwAAgKK/ozeAoSO0AAAAKPo7egMYOkILAACAor+jN4ChSzG7AQAAAFYQ7R29AQwdIy0AAAAALI3QAgAAAMDSCC0AAAAALI3QAgAAAEuJZflpSl3H3lD6nNACAAAAS4ll+WlKXcfeUPqc0AIAAABLiWX5aUpdx95Q+pySxwAAALCUWJafptR17A2lzxlpAQAAAGBphBYAAAAAlkZoAQAAAGBphBYAAAAAlkZoAQAAAGBphBYAAAAAlkZoAQAAAGBphBYAAAAAlkZoAQAAAGBphBYAAAAAlkZoAQAAAGBphBYAAAAAlkZoAQAAAGBphBYAAABIkpbXtGvu601aXtNudlNgEqu+BwgtAAAAkCQtqWrTxt09eryqzeymwCRWfQ8QWgAAACBJWlCZpcnZKfpRZZbZTYFJrPoeSDG7AQAAALCGeeWZmleeaXYzYCKrvgcYaQEAAABgaYQWAAAAAJZGaAEAAABgaYQWAAAAAJZGaAEAAABgaYQWAAAAAJZGaAEAAABgaYQWAAAAAJZGaAEAAABgaYQWAAAAAJZGaAEAAABgaYQWAAAAAJZGaAEAAABgaYQWAAAAAJZGaAEAAABgaYQWAAAAAJZmemh58skndeihh6qwsFAnnHCC3n///ZC3feedd5STkxPw5+uvv45hiwEAAADEUoqZv/yVV17RrbfeqgceeEBHH320nnzySZ1//vlavXq1xo8fH/J+q1ev1pgxY7w/5+XlxaK5AAAAAExga2lpMcz65SeddJKmTZumhx9+2HvZEUccoe9+97tauHBhwO3feecdzZs3Txs3blRubm4smwoAAADAJKZND+vq6tLatWs1Z84cv8vnzJmjDz/8sN/7nnjiiTrooIN01lln6e23345mMwEAAACYzLTpYc3NzXI6ncrPz/e7PD8/X42NjUHvU1RUpEWLFumII45QV1eX/vCHP+i73/2uVqxYoWOPPTYWzQYAAAAQY6auaQlXRUWFKioqvD/PnDlTW7Zs0cMPP0xoAQAAABKUadPDcnNz5XA41NTU5Hd5U1OTCgoKBv04Rx55pL755ptINw8AAACARZgWWtLS0jR9+nStWrXK7/JVq1Zp1qxZg36cf/7znyosLIx08wAAAABYhKnTw6699lrNnz9fRx55pGbNmqVly5apvr5eV1xxhSRp/vz5kqSlS5dKkh577DGVlZVp6tSp6urq0osvvqgVK1bomWeeMe05AAAAAIguUzeXPOecc3Tvvffq/vvv1+zZs7V69Wq9+OKLKisrkyTV1taqtrbWe/vu7m7dcccdOu6443TGGWd4b3/WWWf5PW44G1ZicO69996ATT0PPPBA7/WGYejee+/VlClTVFRUpDPPPFPr16/3e4yWlhZdffXVKisrU1lZma6++mq1tLTE+JlY33vvvacLL7xQU6dOVU5Ojn73u9/5XR+pvv7iiy80d+5cFRUVaerUqfrVr34lwzCtArolDNT3CxYsCPgcnHzyyX636ezs1E033aQDDjhAxcXFuvDCC1VXV+d3m61bt+qCCy5QcXGxDjjgAN18883q6uqK+vOzskWLFunb3/62xo8fr0mTJumCCy5QVVWV321470fHYPqe9350PPHEEzr22GM1fvx4jR8/Xqeccor++te/eq/nPR89A/U973nrMTW0SNKVV16pf/7zn2psbNRbb72l4447znvdihUrtGLFCu/P119/vT755BPV19erpqZGb7zxhk499VS/x/NsWHnDDTfo7bff1syZM3X++edr69atMXtOiaqiokJfffWV949vGHzooYe0ePFi/epXv9LKlSuVn5+v733ve9qzZ4/3NldeeaXWrVunl19+WS+//LLWrVvnHU3Dfnv37lVlZaXuu+8+ZWZmBlwfib7evXu3vve976mgoEArV67Ufffdp0ceeUSPPvpoTJ6jVQ3U95K75Lrv5+Cll17yu/62227T8uXL9dRTT+n111/Xnj17dMEFF8jpdEqSnE6nLrjgArW1ten111/XU089pddee00///nPo/78rOzdd9/Vv/zLv+ivf/2rXnvtNaWkpOjss8/Wrl27vLfhvR8dg+l7ifd+NBQXF+uuu+7SW2+9pVWrVun444/XJZdcos8//1wS7/loGqjvJd7zVmPq5pLREO6GlRice++9V6+99po++OCDgOsMw9CUKVN01VVX6cYbb5Qktbe3q6KiQnfffbeuuOIKffXVV5o1a5b+8pe/6Oijj5YkffDBBzrjjDP00Ucf+VWFw34lJSX69a9/rUsuuURS5Pr6qaee0p133qmvv/7ae3B+//33a9myZaqqqpLNZjPnCVtI376X3Gfedu7cqT/84Q9B79Pa2qrJkydr8eLF+v73vy/JPWJ8yCGH6OWXX9ZJJ52k//3f/9X3v/99/fOf/1Rpaakk6Q9/+IN+/OMfq7q6WtnZ2dF/cnGgra1NZWVl+t3vfqczzjiD934M9e17ifd+LJWXl2vhwoW6/PLLec/HmKfvr7jiCt7zFmT6SEskDWfDSgyspqZGU6ZM0aGHHqof/vCHqqmpkSRt3rxZDQ0Nfv2emZmpY4891tvva9asUVZWll+RhaOPPlojR47ktQlDpPp6zZo1OuaYY/xGE0466SRt375dmzdvjtGziU8ffPCBJk+erCOPPFI//vGP/Sogrl27Vt3d3X6vT2lpqQ466CC/vj/ooIO8/4FJ7r7v7OzU2rVrY/Y8rK6trU0ul0s5OTmSeO/HUt++9+C9H11Op1N//OMftXfvXs2cOZP3fAz17XsP3vPWElf7tAxkKBtWYnCOOuooPfbYY6qoqNCOHTt0//3369RTT9Xq1avV0NAgSUH7ffv27ZKkxsZG5ebm+p3RsdlsysvL47UJQ6T6urGxUcXFxQGP4bmuvLw8Wk8hrp188smaN2+eJkyYoC1btujf//3fddZZZ+nvf/+70tPT1djYKIfDodzcXL/7+X4HNTY2Brx+nhLwfBb2u/XWW3XIIYd4DyB478dO376XeO9H0xdffKFTTz1VHR0dGjlypJ577jlNmzbNe+DLez56QvW9xHveihIqtCB6TjnlFL+fjzrqKE2fPl2///3vNWPGDJNaBcTWueee6/33tGnTNH36dB1yyCH661//GlAQBEP3s5/9TKtXr9Zf/vIXORwOs5uTVEL1Pe/96KmoqNA777yj3bt369VXX9WCBQv05z//2exmJYVQfV9ZWcl73oISanpYpDasxMCysrI0ZcoUffPNN959cvrr94KCAjU3N/tVKzEMQzt27OC1CUOk+rqgoCDoY3iuw+CMGzdOxcXF3g1uCwoK5HQ61dzc7He7vq9P3773jBLT9+6FrX/84x/12muv+Z0B5r0ffaH6Phje+5GTlpamAw44QNOnT9fChQt1yCGH6LHHHuM9HwOh+j4Y3vPmS6jQEqkNKzGwjo4OVVdXq7CwUBMmTFBhYaFfv3d0dOiDDz7w9vvMmTPV1tamNWvWeG+zZs0a7d27l9cmDJHq65kzZ+qDDz5QR0eH9zarVq3SuHHjNGHChBg9m/jX3Nys7du3ew8upk+frtTUVL/Xp66uzrtYVnL3/VdffeVXFnPVqlVKT0/X9OnTY9p+q7nlllu8B82+JdUl3vvR1l/fB8N7P3pcLpe6urp4z5vA0/fB8J43X0KFFsm9YeXvf/97PfPMM/rqq690yy23+G1YiaG5/fbb9e6776qmpkYff/yxLrvsMu3bt08XXXSRbDabFixYoIceekivvfaaqqqqdM0112jkyJE677zzJEkHHXSQTj75ZP30pz/VmjVrtGbNGv30pz/VaaedRuWwPtra2rRu3TqtW7dOLpdLtbW1WrdunbZu3Rqxvj7vvPOUmZmpa665RlVVVXrttdf0m9/8Rtdcc01SV5Lpr+/b2tp0++23a82aNdq8ebPeeecdXXjhhcrPz9d3vvMdSdLo0aN16aWXauHChfr73/+uzz77TPPnz9e0adN04oknSnIXBpk6dap+9KMf6bPPPtPf//533XHHHfrBD36Q1JVkbrzxRv3+97/XE088oZycHDU0NKihoUFtbW2SxHs/igbqe9770XPnnXfq/fff1+bNm/XFF1/orrvu0rvvvqvzzz+f93yU9df3vOetKeFKHkvuzSUfeughNTQ0aOrUqbrnnnv89n9B+H74wx/q/fffV3Nzs/Ly8nTUUUfp5z//uaZMmSLJPRx933336emnn1ZLS4uOPPJI/ed//qcqKyu9j9HS0qKbb75Zb7zxhiTpjDPO0K9//euACjXJ7p133tG8efMCLr/ooou0ZMmSiPX1F198oRtvvFGffPKJcnJydMUVV+iWW25J6v/E+uv7RYsW6ZJLLtG6devU2tqqwsJCzZ49Wz//+c/9KsN0dnbq9ttv18svv6yOjg4df/zxeuCBB/xus3XrVt144416++23lZGRofPPP19333230tPTY/I8rSjU98Att9yi2267TVLkvmd47/sbqO/b29t570fJggUL9M4776ixsVHZ2dmaNm2afvzjH+ukk06SxHs+mvrre97z1pSQoQUAAABA4ki46WEAAAAAEguhBQAAAIClEVoAAAAAWBqhBQAAAIClEVoAAAAAWBqhBQAAAIClEVoAwATvvPOOcnJy9Mc//tHspgzakiVLNH36dI0dO1bf+ta3zG5ORP3ud79TTk6ONm/ebHZTTON5T77zzjtmNwUAAhBaAAAD+uCDD3TbbbfpyCOP1KOPPqo77rjD7CZZxvbt23Xvvfdq3bp1ZjdlUB544AH9+c9/NrsZABCWFLMbAACwvnfffVeStGjRIo0ePdrk1kTehRdeqHPPPXdIu1TX19frV7/6lcrKynTooYdGoXWRtWjRIp111ln6zne+43f5cccdp/r6eqWlpZnUMgAIjZEWAEhge/fujcjjNDU1SVJCBhZJcjgcysjIkM1mM7spXpF67QbLbrcrIyNDdjuHBgCsh28mAAnv3nvvVU5Ojqqrq7VgwQKVlZWprKxM11xzjfbt2+e93ebNm5WTk6Pf/e53AY+Rk5Oje++9N+Axv/rqK1199dUqKyvTAQccoF/+8pcyDEPbtm3TxRdfrPHjx6uiokIPP/xw0LY5nU7dc889mjJlisaNG6dzzjlHGzduDLjdhg0bdPnll2vixIkqLCzU7Nmz9eqrr/rdxrMu46233tLNN9+siooKlZSU9Ns3TqdT//mf/6nDDz9cBQUFOvjgg3XHHXeovb3d77n/13/9l/ffofrIo7GxUdddd52mTZumgoICVVRU6LzzztP69ev9brdy5UrNnTtXJSUlKikp0bnnnht0ilU4z/3dd9/Vz372M02aNEnFxcW65JJLtGPHjn77wPf+vmtazjzzTM2YMUNffvml5s2bp3Hjxmnq1Kl66KGHvLd555139O1vf1uSdO2113r7x/e9MtzXbteuXfrFL36hY489VqWlpSopKdGZZ56p999/P+B5GIahJ554Qt/61rdUVFSkAw44QGeffbb3tjk5Odq7d6+ef/55b1vPPPNM73MJtqbl3Xff1dy5c1VcXKyysjJdcMEFqqqq8rvNYD9jkvTWW2/pjDPO0IQJEzRu3DhNnz5dN91004CvEYDkxvQwAEnjhz/8ocrLy7Vw4UJ99tlneuaZZ5Sfn6+77rpryI/5L//yLzrwwAO1cOFC/e1vf9OiRYs0ZswYPffcczr22GN155136qWXXtIdd9yhww47TCeccILf/X/zm9/I5XLpX//1X9XS0qKlS5dq3rx5eu+99zRmzBhJ0ldffaVTTz1VhYWFuv766zVy5Ej9+c9/1mWXXaalS5fqggsu8HvMW265RTk5Obrhhhu0e/fuftv/k5/8RM8++6zmzZuna6+9Vp9++qkefvhhrV+/Xi+++KJsNpuWLl2qF154QatWrdLSpUslSbNmzQr5mJdddpm++OILb5hrbm7We++9pw0bNmjq1KmSpJdeeklXX321vv3tb+uOO+5QV1eXnn76ac2dO1crV67UgQceOKTnftttt2nMmDG65ZZbtGXLFi1ZskQ33XST/vu//3sQr2ag3bt367zzztN3vvMdnX322Xr11Ve1cOFCVVZW6pRTTtFBBx2kn/3sZ7rnnnt0+eWX65hjjpEkTZs2bUjtD/ba1dTU6NVXX9X3vvc9lZeXq7W1Vc8++6zOPvtsrVy5UgcffLD3/tdff72eeeYZnXTSSbr44otlGIbWrFmj999/X8cee6yWLl2qH//4xzriiCN0+eWXS5IKCgpCPv+3335b55xzjiZMmKBbb71VHR0devLJJ3X66adr5cqVmjx5st/tB/qMffnll/r+97+vyspK3XrrrRoxYoQ2bdqkN998c0ivD4DkQWgBkDQOPfRQLV682Pvzzp079eyzzw4rtEyfPl2PPvqoJOnyyy/XoYceqjvuuEM///nPdeONN0qSzj33XE2dOlW/+93vAkJLU1OTPvroI+Xk5EiSZs+ere9+97tavHixbr/9dknSrbfeqnHjxmnVqlXKzMyUJF111VX63ve+p7vuukvf//73/aY1eQ6MU1L6/4r//PPP9eyzz+riiy/WY4895r28tLRUv/rVr/TXv/5Vp59+ui644AJ9/PHHWrVqVcBBdl8tLS364IMPdPfdd+u6667zXv7Tn/7U+++9e/fqpptu0sUXX+z3elx66aU66qij9Otf/1pPPvnkkJ772LFj9ac//cl7mcvl0tKlS9Xa2jqkqW0NDQ1asmSJLrroIm8bDznkED377LM65ZRTVFBQoFNOOUX33HOPZsyYEdA/kXjtKisrtXbtWr9pW5dffrlmzJihpUuX6pFHHpHkHil55plndOWVV+o///M/vbe99tprZRiGJOmCCy7Qv/3bv6m8vHzA11KSbr/9dmVnZ+t///d/NXbsWEnu9/PRRx+tX/7yl3rmmWf8bj/QZ2zVqlXq7OzUyy+/rNzcXO/t7rzzzgHbAiC5MT0MQNK47LLL/H4+5phjtHPnzgFHI/rzgx/8wPtvh8Oh6dOnyzAMXXrppd7Lc3JyNHnyZNXU1ATc/8ILL/QGFkk64YQTNHXqVP3lL3+R5J4a9Pe//11nn3229u3bp+bmZu+fk046Sdu2bdOGDRsCnudAgUWS/va3v0lyH9T6uuaaa+RwOLzXhyMzM1NpaWl69913tWvXrqC3WbVqlVpaWnT++ef7PR+n06ljjjnGOz1pKM/90ksv9QsBxxxzjJxOp7Zu3Rr2c/E8H9+D+7S0NB1xxBFBX8u+IvXapaenewNLR0eHdu7cKafTqSOOOEJr16713u61116T5B5t6msoa3Xq6+u1bt06XXTRRd7AIkmTJk3SGWecoTfffFNOpzOg/b76fsays7MlSStWrJDL5Qq7TQCSFyMtAJJGaWmp38+esNDS0uI9mBruY2ZnZys1NVWFhYUBl3sWs/uaNGlS0MvefvttSdI333wjwzB033336b777gvahqamJlVUVHh/Li8vH1Tbt27dKpvNFjDFZ/To0SoqKtKWLVsG9Ti+0tPTdeedd+oXv/iFKioqdNRRR+mUU07RBRdc4O0rz5qds88+O+hjeA7Qh/Lc+3uNh2LcuHEBC9NzcnL0xRdfDHjfSL12LpdLDz30kJ5++umAfWQmTJjg/femTZtUUFDgN4IxHJ6g59s+jwMPPFCvvfaampub/aaXDfQZO+ecc/Tcc8/pxz/+se68804df/zxOvPMM/W9731vUEEbQPLiGwJA0nA4HEEv90ydCXU2uu/Z5IEeM1T1Jc/vCYfnbPQ111yjU089NehtKisr/X72TEMyyzXXXKO5c+fq9ddf19///nfdf//9WrRokV544QXNnj3b+5wee+wxFRcXh3ycoTz3gV7jcA3n8SL12i1atEj//u//rosuuki33367xo4dK4fDoUWLFmnTpk0DtiOWBuqvzMxMrVixQu+9957+93//V2+++aauuuoqLV68WG+88Ybp710A1kVoAYBenrPCra2tfpcPdWrRYASrFLZx40aVlZVJ2n/mPSUlRSeeeGJEf/f48eNlGIY2bNjgXTguuRef19fX67TTThvyY5eXl+uaa67RNddco7q6Os2ePVsPPPCAZs+erYkTJ0qS8vLy+n1O0XzukRQq7Eaq/X/605/0rW99S0uWLPG73LdCmSRNnDhR//d//6cdO3YoLy8v7Pb2NX78eElSdXV1wHXV1dUaOXLkkEZ17Ha7Zs+erdmzZ+uXv/ylnnrqKd1www1avny5vv/974f9eACSA2taAKBXdna2cnNzA0rJehaFR8MLL7zgN3Xprbfe0vr1672BIT8/X7Nnz9Zvf/tbbdu2LeD+gynnG4rn7H/fg+HHH39cTqdzSKFl3759fuWSJamkpET5+fneMDhnzhyNHj1aixYtUldXV8BjeJ5TNJ97JI0YMUJS4BS0SLXf4XAEjOx8+OGHWrNmjd9lZ511liQFnYrme/8RI0YMarpcUVGRDjvsML3wwgt+65M2bdqkN954QyeffHLIkZVQdu7cGXDZYYcdJinwZAEA+GKkBQB8/OAHP9CDDz6o6667Tocffrjef//9gMXSkZSfn6/TTz9d/+///T+1trbq8ccfV1FRkd/i+EWLFum0007Tcccdp8suu0wTJ05UU1OTPv74Y3311Vf69NNPh/S7Dz74YF166aV69tlntXv3bh1//PH67LPP9Nxzz+nkk08OOaWpPxs2bNBZZ52ls88+W1OmTFF6err+9re/6auvvtLdd98tyR0OH3zwQV111VU6/vjjde6556qgoEBbt27Vm2++qSlTpniDVLSeeyRNnDhROTk5WrZsmbKyspSVlaWpU6eqsrIyIu0/44wzdN9992n+/Pk69thjtXHjRj399NOaMmWK2travLebPXu2Lr74Yj355JPatGmTTj75ZEnSRx99pGnTpumGG26QJB1++OF666239Mgjj6i4uFh5eXkBVe087r77bp1zzjk65ZRTdNlll3lLHmdkZOgXv/hF2H3161//Wu+++65OO+00lZWVqaWlRcuWLdPIkSOHNbIHIPERWgDAx80336wdO3bo1Vdf1Z/+9CedfPLJevnllwMWq0fKT37yE1VXV+uRRx5Ra2urjjnmGP3617/2q9ZUUVGhVatW6Ve/+pVeeOEFNTc3Ky8vTwcffLB+/vOfD+v3/+Y3v9GECRP03HPP6Y033lBBQYGuu+463XbbbUOqOFVaWqrzzz9fb7/9tl5++WXZbDZNmjRJjzzyiF9FtXPOOUdFRUVatGiRHn30UXV2dqqoqEizZs3SFVdcEZPnHimpqalaunSp7rrrLt14443q7u7WLbfcosrKyoi0/9/+7d/U3t6ul156Sa+++qqmTp2qZcuW6Y9//KPeffddv9s++uijmjZtmp599lktXLhQWVlZOuyww3Tcccd5b3PPPffoJz/5ie677z7t3btXxx13XMjQcvzxx+t//ud/dM899+iee+5RSkqKjjnmGC1cuHBIn4m5c+eqtrZWzz//vHbs2KGxY8dqxowZuvnmm71TIgEgGFtLS8vQVicCAAAAQAywpgUAAACApRFaAAAAAFgaoQUAAACApRFaAAAAAFgaoQUAAACApRFaAAAAAFgaoQUAAACApRFaAAAAAFgaoQUAAACApf1/6XuCloZcrecAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def roc_score_per_interaction(x):\n",
    "    try:\n",
    "        return roc_auc_score(x.answered_correctly.values, x.predictions.values)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "df[\"num_iteractions\"] = (df.groupby(\"user_id\").cumcount() // 10) * 10\n",
    "interactions_auc = df.groupby(\"num_iteractions\").apply(roc_score_per_interaction)\n",
    "interactions_auc = interactions_auc[~interactions_auc.isna()].copy()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.regplot(\n",
    "    y=interactions_auc.values,\n",
    "    x=interactions_auc.index,\n",
    "    line_kws={\"color\": \"red\", \"linewidth\": 2},\n",
    "    scatter_kws={\"s\": 3},\n",
    ")\n",
    "ax.set_ylim(0.5, 1)\n",
    "ax.set_xlim(0, interactions_auc.index.max())\n",
    "ax.set_ylabel(\"auc\")\n",
    "ax.set_xlabel(\"number of seen interactions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Iter_Valid(object):\n",
    "    def __init__(self, df, max_user=1000):\n",
    "        df = df.reset_index(drop=True)\n",
    "        self.df = df\n",
    "        self.user_answer = df[\"user_answer\"].astype(str).values\n",
    "        self.answered_correctly = df[\"answered_correctly\"].astype(str).values\n",
    "        df[\"prior_group_responses\"] = \"[]\"\n",
    "        df[\"prior_group_answers_correct\"] = \"[]\"\n",
    "        self.sample_df = df[df[\"content_type_id\"] == 0][[\"row_id\"]]\n",
    "        self.sample_df[\"answered_correctly\"] = 0\n",
    "        self.len = len(df)\n",
    "        self.user_id = df.user_id.values\n",
    "        self.task_container_id = df.task_container_id.values\n",
    "        self.content_type_id = df.content_type_id.values\n",
    "        self.max_user = max_user\n",
    "        self.current = 0\n",
    "        self.pre_user_answer_list = []\n",
    "        self.pre_answered_correctly_list = []\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def fix_df(self, user_answer_list, answered_correctly_list, pre_start):\n",
    "        df = self.df[pre_start : self.current].copy()\n",
    "        sample_df = self.sample_df[pre_start : self.current].copy()\n",
    "        df.loc[pre_start, \"prior_group_responses\"] = (\n",
    "            \"[\" + \",\".join(self.pre_user_answer_list) + \"]\"\n",
    "        )\n",
    "        df.loc[pre_start, \"prior_group_answers_correct\"] = (\n",
    "            \"[\" + \",\".join(self.pre_answered_correctly_list) + \"]\"\n",
    "        )\n",
    "        self.pre_user_answer_list = user_answer_list\n",
    "        self.pre_answered_correctly_list = answered_correctly_list\n",
    "        return df, sample_df\n",
    "\n",
    "    def __next__(self):\n",
    "        added_user = set()\n",
    "        pre_start = self.current\n",
    "        pre_added_user = -1\n",
    "        pre_task_container_id = -1\n",
    "\n",
    "        user_answer_list = []\n",
    "        answered_correctly_list = []\n",
    "        while self.current < self.len:\n",
    "            crr_user_id = self.user_id[self.current]\n",
    "            crr_task_container_id = self.task_container_id[self.current]\n",
    "            crr_content_type_id = self.content_type_id[self.current]\n",
    "            if crr_content_type_id == 1:\n",
    "                # no more than one task_container_id of \"questions\" from any single user\n",
    "                # so we only care for content_type_id == 0 to break loop\n",
    "                user_answer_list.append(self.user_answer[self.current])\n",
    "                answered_correctly_list.append(self.answered_correctly[self.current])\n",
    "                self.current += 1\n",
    "                continue\n",
    "            if crr_user_id in added_user and (\n",
    "                (crr_user_id != pre_added_user)\n",
    "                or (crr_task_container_id != pre_task_container_id)\n",
    "            ):\n",
    "                # known user(not prev user or differnt task container)\n",
    "                return self.fix_df(user_answer_list, answered_correctly_list, pre_start)\n",
    "            if len(added_user) == self.max_user:\n",
    "                if (\n",
    "                    crr_user_id == pre_added_user\n",
    "                    and crr_task_container_id == pre_task_container_id\n",
    "                ):\n",
    "                    user_answer_list.append(self.user_answer[self.current])\n",
    "                    answered_correctly_list.append(\n",
    "                        self.answered_correctly[self.current]\n",
    "                    )\n",
    "                    self.current += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    return self.fix_df(\n",
    "                        user_answer_list, answered_correctly_list, pre_start\n",
    "                    )\n",
    "            added_user.add(crr_user_id)\n",
    "            pre_added_user = crr_user_id\n",
    "            pre_task_container_id = crr_task_container_id\n",
    "            user_answer_list.append(self.user_answer[self.current])\n",
    "            answered_correctly_list.append(self.answered_correctly[self.current])\n",
    "            self.current += 1\n",
    "        if pre_start < self.current:\n",
    "            return self.fix_df(user_answer_list, answered_correctly_list, pre_start)\n",
    "        else:\n",
    "            raise StopIteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "inference_dataset = InferenceRIIDDataset(hdf5_file=\"feats_train.h5\",)\n",
    "iter_test = Iter_Valid(valid,max_user=1000)\n",
    "predicted = []\n",
    "def set_predict(df):\n",
    "    predicted.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac18994dbb7434e8e8694d8580451a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2500000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pbar = tqdm(total=len(valid))\n",
    "previous_test_df = None\n",
    "for (current_test, current_prediction_df) in iter_test:\n",
    "    if previous_test_df is not None:\n",
    "        previous_test_df[\"answered_correctly\"] = eval(\n",
    "            current_test[\"prior_group_answers_correct\"].iloc[0]\n",
    "        )\n",
    "        previous_test_df[previous_test_df.content_type_id == 0].groupby(\n",
    "            \"user_id\"\n",
    "        ).answered_correctly.apply(inference_dataset.update_answered_correctly)\n",
    "\n",
    "    # your feature extraction and model training code here\n",
    "    previous_test_df = current_test.copy()\n",
    "\n",
    "    # add current to cache\n",
    "    current_test = current_test[current_test.content_type_id == 0]\n",
    "    current_test = add_part_to_questions(current_test)\n",
    "    current_test[[\"row_id\", \"user_id\", \"content_id\", \"part\", \"timestamp\"]].groupby(\n",
    "        \"user_id\"\n",
    "    ).apply(lambda user_rows: inference_dataset.update_user_rows(user_rows))\n",
    "\n",
    "    # your prediction code here\n",
    "    current_test = predict_for_df(current_test)\n",
    "    set_predict(current_test.loc[:, [\"row_id\", \"answered_correctly\"]])\n",
    "    pbar.update(len(current_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation auc: 0.7301190955694308\n"
     ]
    }
   ],
   "source": [
    "#validation score\n",
    "y_pred = pd.concat(predicted).answered_correctly\n",
    "y_true = valid[valid.content_type_id == 0].answered_correctly[:len(y_pred)]\n",
    "\n",
    "print('validation auc:',roc_auc_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
